{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, text, inspect, Text, Integer, BigInteger, Float, Boolean\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "# API\n",
    "AUTH_URL = os.getenv('AUTH_URL')\n",
    "ACTIVITIES_URL = os.getenv('ACTIVITIES_URL')\n",
    "ACTIVITY_DETAIL_URL_TMPL = os.getenv('ACTIVITY_DETAIL_URL_TMPL')\n",
    "\n",
    "# DB\n",
    "DB_URI = os.getenv('DB_URI')\n",
    "\n",
    "# Bronze tables\n",
    "TARGET_B_SCHEMA = os.getenv('TARGET_B_SCHEMA')\n",
    "ACTIVITIES_B_TABLE = os.getenv('ACTIVITIES_B_TABLE')\n",
    "DETAILS_B_TABLE = os.getenv('DETAILS_B_TABLE')\n",
    "\n",
    "# Pagination\n",
    "PER_PAGE = int(os.getenv('PER_PAGE'))\n",
    "MAX_PAGES = int(os.getenv('MAX_PAGES'))\n",
    "\n",
    "# Timeouts and retries\n",
    "REQUEST_TIMEOUT = int(os.getenv('REQUEST_TIMEOUT'))\n",
    "MAX_RETRIES = int(os.getenv('MAX_RETRIES'))\n",
    "BASE_SLEEP = float(os.getenv('BASE_SLEEP'))\n",
    "\n",
    "# Other\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL.upper(), logging.INFO),\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_ENV = ['CLIENT_ID', 'CLIENT_SECRET', 'REFRESH_TOKEN']\n",
    "missing_env = [env for env in REQUIRED_ENV if not os.getenv(env)]\n",
    "if missing_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_env)}.\")\n",
    "\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:02,765 | INFO | Connection created and bronze schema exists.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "  DB_URI, \n",
    "  pool_pre_ping=True, \n",
    "  pool_size=5, \n",
    "  max_overflow=10\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "  conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_B_SCHEMA};\"))\n",
    "logging.info(f\"Connection established and {TARGET_B_SCHEMA} schema exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:03,129 | INFO | Access token retrived.\n"
     ]
    }
   ],
   "source": [
    "def get_access_token(auth_url: str, client_id: str, client_secret: str, refresh_token: str, timeout: int = 30) -> str:\n",
    "  \"\"\"\n",
    "  Request a new access token from an OAuth2 authentication endpoint.\n",
    "\n",
    "  The function uses a refresh token to obtain a short-lived access token. \n",
    "  If the response does not contain an ``access_token``, a RuntimeError is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  auth_url : str\n",
    "      URL of the OAuth2 token endpoint.\n",
    "  client_id : str\n",
    "      OAuth2 client identifier.\n",
    "  client_secret : str\n",
    "      OAuth2 client secret.\n",
    "  refresh_token : str\n",
    "      Refresh token used to request a new access token.\n",
    "  timeout : int, default=30\n",
    "      Timeout in seconds for the HTTP request.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  str\n",
    "      The access token string retrieved from the authentication server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the response does not include an ``access_token``.\n",
    "  requests.exceptions.RequestException\n",
    "      If the HTTP request fails (e.g., network error, timeout).\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  Logs an informational message when the token is successfully retrieved.\n",
    "  \"\"\"\n",
    "\n",
    "  payload = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'refresh_token': refresh_token,\n",
    "    'grant_type': 'refresh_token',\n",
    "  }\n",
    "  res = requests.post(auth_url, data=payload, timeout=timeout)\n",
    "  data = res.json()\n",
    "  token = data.get('access_token')\n",
    "  if not token:\n",
    "    raise RuntimeError(f\"No access token in response: {data}\")\n",
    "  logging.info('Access token retrived.')\n",
    "  return token\n",
    "\n",
    "access_token = get_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"Authorization\": f\"Bearer {access_token}\"})\n",
    "\n",
    "def get_json_with_retry(url: str, params=None, max_retries: int = MAX_RETRIES, timeout: int = REQUEST_TIMEOUT, base_sleep: float = BASE_SLEEP):\n",
    "  \"\"\"\n",
    "  Send a GET request with automatic retries and return the parsed JSON response.\n",
    "\n",
    "  The function retries on:\n",
    "    * HTTP 429 (rate limiting) ‚Äî respects the ``Retry-After`` header if present,\n",
    "      otherwise waits an increasing backoff time.\n",
    "    * HTTP 5xx errors ‚Äî retries with exponential backoff and jitter.\n",
    "    * Network/connection errors ‚Äî retries with exponential backoff and jitter.\n",
    "\n",
    "  For each attempt, the backoff time increases by ``base_sleep * attempt`` seconds\n",
    "  plus a small random jitter. On the final attempt, any error is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  url : str\n",
    "      Endpoint URL to send the GET request to.\n",
    "  params : dict, optional\n",
    "      Query string parameters to include in the request.\n",
    "  max_retries : int, default=MAX_RETRIES\n",
    "      Maximum number of retry attempts before failing.\n",
    "  timeout : int, default=REQUEST_TIMEOUT\n",
    "      Timeout in seconds for each HTTP request.\n",
    "  base_sleep : float, default=BASE_SLEEP\n",
    "      Base number of seconds used for exponential backoff between retries.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      Parsed JSON response from the server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after all retry attempts.\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns a 4xx/5xx response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * HTTP 429 triggers a wait using ``Retry-After`` if available, otherwise a fallback.\n",
    "  * Logs warnings before each retry and errors if JSON parsing fails.\n",
    "  * Uses a global ``requests.Session`` (`session`) for connection pooling.\n",
    "  \"\"\"\n",
    "\n",
    "  for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "      resp = session.get(url, params=params, timeout=timeout)\n",
    "      \n",
    "      if resp.status_code == 429:\n",
    "        retry_after = resp.headers.get('Retry-After')\n",
    "        if retry_after and retry_after.isdigit():\n",
    "          sleep_for = int(retry_after)\n",
    "        else:\n",
    "          sleep_for = max(base_sleep * attempt, 15)\n",
    "        logging.warning(f\"HTTP 429 - wait {sleep_for}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      if 500 <= resp.status_code < 600:\n",
    "        if attempt == max_retries:\n",
    "          resp.raise_for_status()\n",
    "        sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "        logging.warning(f\"HTTP {resp.status_code} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      resp.raise_for_status()\n",
    "\n",
    "      try:\n",
    "        return resp.json()\n",
    "      except json.JSONDecodeError:\n",
    "        logging.error('JSON parsing error')\n",
    "        raise\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "      if attempt == max_retries:\n",
    "        logging.exception('Request error (last attempt)')\n",
    "        raise\n",
    "      sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "      logging.warning(f\"{e} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "      time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting activities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:09,266 | INFO | Page 1: downloaded 200 records (total: 200)\n",
      "2025-09-15 16:04:14,009 | INFO | Page 2: downloaded 200 records (total: 400)\n",
      "2025-09-15 16:04:18,518 | INFO | Page 3: downloaded 200 records (total: 600)\n",
      "2025-09-15 16:04:23,538 | INFO | Page 4: downloaded 200 records (total: 800)\n",
      "2025-09-15 16:04:28,072 | INFO | Page 5: downloaded 200 records (total: 1000)\n",
      "2025-09-15 16:04:29,216 | INFO | Page 6: downloaded 91 records (total: 1091)\n",
      "2025-09-15 16:04:29,418 | INFO | Total activities downloaded: 1091\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_count</th>\n",
       "      <th>total_photo_count</th>\n",
       "      <th>has_kudoed</th>\n",
       "      <th>suffer_score</th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>athlete_resource_state</th>\n",
       "      <th>map_id</th>\n",
       "      <th>map_summary_polyline</th>\n",
       "      <th>map_resource_state</th>\n",
       "      <th>average_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>15km Long Run‚òîÔ∏è</td>\n",
       "      <td>15059.0</td>\n",
       "      <td>5461</td>\n",
       "      <td>5488</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15805849875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>66.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15805849875</td>\n",
       "      <td>w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tempo 4kmüòÆ‚Äçüí®</td>\n",
       "      <td>7531.2</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15798063578</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15798063578</td>\n",
       "      <td>us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6km Easy Runüòå</td>\n",
       "      <td>6062.9</td>\n",
       "      <td>2140</td>\n",
       "      <td>2140</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15786538213</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15786538213</td>\n",
       "      <td>kh|vHguogBJ\\JNHFRBN?fBc@\\FZ`@JXdAzBp@xAHFRBNAh...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3576</td>\n",
       "      <td>3576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Workout</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15775473094</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15775473094</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7.5km Easy Runüòå</td>\n",
       "      <td>7556.8</td>\n",
       "      <td>2651</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15766076458</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>30.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15766076458</td>\n",
       "      <td>k_|vHcpogB^v@b@dAJNNHT@n@Q\\GTARBRHPRd@r@FRBv@J...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               2            15km Long Run‚òîÔ∏è   15059.0         5461   \n",
       "1               2               Tempo 4kmüòÆ‚Äçüí®    7531.2         2400   \n",
       "2               2              6km Easy Runüòå    6062.9         2140   \n",
       "3               2  Afternoon Weight Training       0.0         3576   \n",
       "4               2            7.5km Easy Runüòå    7556.8         2651   \n",
       "\n",
       "   elapsed_time  total_elevation_gain     type      sport_type  workout_type  \\\n",
       "0          5488                  31.0      Run             Run           2.0   \n",
       "1          2400                  11.0      Run             Run           3.0   \n",
       "2          2140                  17.0      Run             Run           NaN   \n",
       "3          3576                   0.0  Workout  WeightTraining           NaN   \n",
       "4          2651                  11.0      Run             Run           0.0   \n",
       "\n",
       "            id  ... pr_count total_photo_count has_kudoed  suffer_score  \\\n",
       "0  15805849875  ...        0                 0      False          66.0   \n",
       "1  15798063578  ...        0                 0      False          53.0   \n",
       "2  15786538213  ...        0                 0      False          24.0   \n",
       "3  15775473094  ...        0                 0      False           8.0   \n",
       "4  15766076458  ...        0                 0      False          30.0   \n",
       "\n",
       "  athlete_id athlete_resource_state        map_id  \\\n",
       "0   81055898                      1  a15805849875   \n",
       "1   81055898                      1  a15798063578   \n",
       "2   81055898                      1  a15786538213   \n",
       "3   81055898                      1  a15775473094   \n",
       "4   81055898                      1  a15766076458   \n",
       "\n",
       "                                map_summary_polyline  map_resource_state  \\\n",
       "0  w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...                   2   \n",
       "1  us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...                   2   \n",
       "2  kh|vHguogBJ\\JNHFRBN?fBc@\\FZ`@JXdAzBp@xAHFRBNAh...                   2   \n",
       "3                                                                      2   \n",
       "4  k_|vHcpogB^v@b@dAJNNHT@n@Q\\GTARBRHPRd@r@FRBv@J...                   2   \n",
       "\n",
       "   average_temp  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_all_activities(activites_url: str, per_page: int = PER_PAGE, max_pages: int = MAX_PAGES):\n",
    "  \"\"\"\n",
    "  Fetch all activity records from a paginated API endpoint.\n",
    "\n",
    "  The function iterates through API pages until either:\n",
    "    * the maximum number of pages is reached (``max_pages``), or\n",
    "    * the API returns an empty list (end of results).\n",
    "\n",
    "  Each page is retrieved using ``get_json_with_retry`` to ensure resilience\n",
    "  against transient errors (rate limits, timeouts, 5xx responses).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activites_url : str\n",
    "      The base URL of the activities endpoint (must support ``per_page`` and ``page`` query params).\n",
    "  per_page : int, default=PER_PAGE\n",
    "      Number of activity records to request per page.\n",
    "  max_pages : int, default=MAX_PAGES\n",
    "      Maximum number of pages to fetch before stopping.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  list of dict\n",
    "      Combined list of activity objects returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the API response is not a list (unexpected schema).\n",
    "  requests.exceptions.RequestException\n",
    "      If the underlying HTTP requests fail after retries.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Logs the number of records downloaded per page and the running total.\n",
    "  * Stops early if the API returns an empty list before reaching ``max_pages``.\n",
    "  * The total number of records is ``per_page * n_pages`` at most.\n",
    "  \"\"\"\n",
    "\n",
    "  all_items = []\n",
    "  page = 1\n",
    "  while page <= max_pages:\n",
    "    params = {'per_page': per_page, 'page': page}\n",
    "    data = get_json_with_retry(activites_url, params=params)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "      raise RuntimeError(f\"Unexpected response type for page {page}: {type(data)} ‚Äî expected list\")\n",
    "    \n",
    "    if not data:\n",
    "      break\n",
    "    \n",
    "    all_items.extend(data)\n",
    "    logging.info(f\"Page {page}: downloaded {len(data)} records (total: {len(all_items)})\")\n",
    "    page += 1\n",
    "  return all_items\n",
    "\n",
    "activities_raw = fetch_all_activities(ACTIVITIES_URL, per_page=PER_PAGE, max_pages=MAX_PAGES)\n",
    "logging.info(f\"Total activities downloaded: {len(activities_raw)}\")\n",
    "activities_df = pd.json_normalize(activities_raw, sep='_')\n",
    "if activities_df.empty:\n",
    "    raise RuntimeError('No activities to save.')\n",
    "activities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"average_temp\": Float,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:29,504 | WARNING | Whole table bronze.activities will be overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_full_name = f\"{TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"\n",
    "logging.warning(f\"Whole table {table_full_name} will be overwritten.\")\n",
    "activities_df.to_sql(\n",
    "  ACTIVITIES_B_TABLE, \n",
    "  engine, \n",
    "  schema=TARGET_B_SCHEMA, \n",
    "  if_exists=\"replace\", \n",
    "  index=False, \n",
    "  method=\"multi\", \n",
    "  chunksize=5000, \n",
    "  dtype=activities_dtype_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing details ‚Äî only `id` that are not present in `bronze.activities_details`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:30,478 | INFO | Missing details of 0 IDs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE} (id BIGINT PRIMARY KEY)\n",
    "\"\"\"))\n",
    "  existing_ids = pd.read_sql(text(f\"SELECT id FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "  existing_ids_set = set(existing_ids['id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids = sorted(all_ids_set - existing_ids_set)\n",
    "logging.info(f\"Missing details of {len(missing_ids)} IDs\")\n",
    "pd.DataFrame({'id': missing_ids}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "2025-09-15 16:04:30,500 | INFO | Details downloaded: 0 / 0\n"
     ]
    }
   ],
   "source": [
    "def fetch_activity_details(activity_id: int):\n",
    "  \"\"\"\n",
    "  Fetch detailed information for a single activity.\n",
    "\n",
    "  Builds the activity detail endpoint URL using the given activity ID\n",
    "  and retrieves the JSON payload with retry logic.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activity_id : int\n",
    "      Unique identifier of the activity.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      JSON object containing the activity details as returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after retries (e.g., network error, rate limit, 5xx).\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns an error response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Uses the global template ``ACTIVITY_DETAIL_URL_TMPL`` to construct the URL.\n",
    "  * Under the hood calls ``get_json_with_retry`` for resiliency.\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_DETAIL_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "details_records = []\n",
    "for i, act_id in tqdm(enumerate(missing_ids, start=1), total=len(missing_ids)):\n",
    "  try:\n",
    "    resp = fetch_activity_details(act_id)\n",
    "    \n",
    "    if not isinstance(resp, dict):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "    details_records.append(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading details for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Details downloaded: {len(details_records)} / {len(missing_ids)}\")\n",
    "details_df_new = pd.json_normalize(details_records, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not details_df_new.empty:\n",
    "  details_df_new = details_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  details_df_new = details_df_new.dropna(how='all')\n",
    "  \n",
    "details_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities_details` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_details_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"description\": Text,\n",
    "    \"calories\": Float,\n",
    "    \"perceived_exertion\": Text,\n",
    "    \"prefer_perceived_exertion\": Text,\n",
    "    \"segment_efforts\": JSONB,\n",
    "    \"splits_metric\": JSONB,\n",
    "    \"splits_standard\": JSONB,\n",
    "    \"laps\": JSONB,\n",
    "    \"best_efforts\": JSONB,\n",
    "    \"stats_visibility\": JSONB,\n",
    "    \"hide_from_home\": Boolean,\n",
    "    \"device_name\": Text,\n",
    "    \"embed_token\": Text,\n",
    "    \"available_zones\": JSONB,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"gear_primary\": Boolean,\n",
    "    \"gear_name\": Text,\n",
    "    \"gear_nickname\": Text,\n",
    "    \"gear_resource_state\": Float,\n",
    "    \"gear_retired\": Boolean,\n",
    "    \"gear_distance\": Float,\n",
    "    \"gear_converted_distance\": Float,\n",
    "    \"photos_primary\": JSONB,\n",
    "    \"photos_count\": Integer,\n",
    "    \"similar_activities_effort_count\": Float,\n",
    "    \"similar_activities_average_speed\": Float,\n",
    "    \"similar_activities_min_average_speed\": Float,\n",
    "    \"similar_activities_mid_average_speed\": Float,\n",
    "    \"similar_activities_max_average_speed\": Float,\n",
    "    \"similar_activities_pr_rank\": Float,\n",
    "    \"similar_activities_frequency_milestone\": Float,\n",
    "    \"similar_activities_trend_speeds\": JSONB,\n",
    "    \"similar_activities_trend_current_activity_index\": Float,\n",
    "    \"similar_activities_trend_min_speed\": Float,\n",
    "    \"similar_activities_trend_mid_speed\": Float,\n",
    "    \"similar_activities_trend_max_speed\": Float,\n",
    "    \"similar_activities_trend_direction\": Float,\n",
    "    \"similar_activities_resource_state\": Float,\n",
    "    \"average_temp\": Float,\n",
    "    \"photos_primary_unique_id\": Text,\n",
    "    \"photos_primary_urls_600\": Text,\n",
    "    \"photos_primary_urls_100\": Text,\n",
    "    \"photos_primary_source\": Integer,\n",
    "    \"photos_primary_media_type\": Integer,\n",
    "    \"photos_use_primary_photo\": Boolean,\n",
    "    \"private_note\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities_details` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:30,520 | INFO | No new details to be saved.\n"
     ]
    }
   ],
   "source": [
    "if details_df_new.empty:\n",
    "  logging.info('No new details to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    details_df_new[0].to_sql(\n",
    "      DETAILS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_details_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE details_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    details_df_new.to_sql(\n",
    "      \"details_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_details_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = details_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in details_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM details_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS details_stg;'))\n",
    "  \n",
    "    logging.info('Activities details saved to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 16:04:30,529 | INFO | Total number of records in bronze.activities: 1091\n",
      "2025-09-15 16:04:30,529 | INFO | Total number of records in bronze.activities_details: 1091\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    total_acts = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"), conn)\n",
    "    total_det = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}: {int(total_acts['n'][0])}\")\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}: {int(total_det['n'][0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strava-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
