{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, text, inspect, Text, Integer, BigInteger, Float, Boolean\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "# API urls\n",
    "AUTH_URL = os.getenv('AUTH_URL')\n",
    "ACTIVITIES_URL = os.getenv('ACTIVITIES_URL')\n",
    "ACTIVITY_DETAIL_URL_TMPL = os.getenv('ACTIVITY_DETAIL_URL_TMPL')\n",
    "ACTIVITY_KUDOS_URL_TMPL = os.getenv('ACTIVITY_KUDOS_URL_TMPL')\n",
    "\n",
    "# API keys\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')\n",
    "\n",
    "# DB\n",
    "DB_URI = os.getenv('DB_URI')\n",
    "\n",
    "# Bronze tables\n",
    "TARGET_B_SCHEMA = os.getenv('TARGET_B_SCHEMA')\n",
    "ACTIVITIES_B_TABLE = os.getenv('ACTIVITIES_B_TABLE')\n",
    "DETAILS_B_TABLE = os.getenv('DETAILS_B_TABLE')\n",
    "KUDOS_B_TABLE = os.getenv('KUDOS_B_TABLE')\n",
    "\n",
    "# Pagination\n",
    "PER_PAGE = int(os.getenv('PER_PAGE'))\n",
    "MAX_PAGES = int(os.getenv('MAX_PAGES'))\n",
    "\n",
    "# Timeouts and retries\n",
    "REQUEST_TIMEOUT = int(os.getenv('REQUEST_TIMEOUT'))\n",
    "MAX_RETRIES = int(os.getenv('MAX_RETRIES'))\n",
    "BASE_SLEEP = float(os.getenv('BASE_SLEEP'))\n",
    "\n",
    "# Other\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL.upper(), logging.INFO),\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_API_ENV = ['CLIENT_ID', 'CLIENT_SECRET', 'REFRESH_TOKEN']\n",
    "missing_api_env = [env for env in REQUIRED_API_ENV if not os.getenv(env)]\n",
    "if missing_api_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_api_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB names validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_DB_ENV = ['DB_URI', 'TARGET_B_SCHEMA', 'ACTIVITIES_B_TABLE', 'DETAILS_B_TABLE']\n",
    "missing_db_env = [env for env in REQUIRED_DB_ENV if not os.getenv(env)]\n",
    "if missing_db_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_db_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:08,258 | INFO | Connection established and bronze schema exists.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "  DB_URI, \n",
    "  pool_pre_ping=True, \n",
    "  pool_size=5, \n",
    "  max_overflow=10\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "  conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_B_SCHEMA};\"))\n",
    "logging.info(f\"Connection established and {TARGET_B_SCHEMA} schema exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:08,773 | INFO | Access token retrived.\n"
     ]
    }
   ],
   "source": [
    "def get_access_token(auth_url: str, client_id: str, client_secret: str, refresh_token: str, timeout: int = 30) -> str:\n",
    "  \"\"\"\n",
    "  Request a new access token from an OAuth2 authentication endpoint.\n",
    "\n",
    "  The function uses a refresh token to obtain a short-lived access token. \n",
    "  If the response does not contain an ``access_token``, a RuntimeError is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  auth_url : str\n",
    "      URL of the OAuth2 token endpoint.\n",
    "  client_id : str\n",
    "      OAuth2 client identifier.\n",
    "  client_secret : str\n",
    "      OAuth2 client secret.\n",
    "  refresh_token : str\n",
    "      Refresh token used to request a new access token.\n",
    "  timeout : int, default=30\n",
    "      Timeout in seconds for the HTTP request.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  str\n",
    "      The access token string retrieved from the authentication server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the response does not include an ``access_token``.\n",
    "  requests.exceptions.RequestException\n",
    "      If the HTTP request fails (e.g., network error, timeout).\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  Logs an informational message when the token is successfully retrieved.\n",
    "  \"\"\"\n",
    "\n",
    "  payload = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'refresh_token': refresh_token,\n",
    "    'grant_type': 'refresh_token',\n",
    "  }\n",
    "  res = requests.post(auth_url, data=payload, timeout=timeout)\n",
    "  data = res.json()\n",
    "  token = data.get('access_token')\n",
    "  if not token:\n",
    "    raise RuntimeError(f\"No access token in response: {data}\")\n",
    "  logging.info('Access token retrived.')\n",
    "  return token\n",
    "\n",
    "access_token = get_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"Authorization\": f\"Bearer {access_token}\"})\n",
    "\n",
    "def get_json_with_retry(url: str, params=None, max_retries: int = MAX_RETRIES, timeout: int = REQUEST_TIMEOUT, base_sleep: float = BASE_SLEEP):\n",
    "  \"\"\"\n",
    "  Send a GET request with automatic retries and return the parsed JSON response.\n",
    "\n",
    "  The function retries on:\n",
    "    * HTTP 429 (rate limiting) ‚Äî respects the ``Retry-After`` header if present,\n",
    "      otherwise waits an increasing backoff time.\n",
    "    * HTTP 5xx errors ‚Äî retries with exponential backoff and jitter.\n",
    "    * Network/connection errors ‚Äî retries with exponential backoff and jitter.\n",
    "\n",
    "  For each attempt, the backoff time increases by ``base_sleep * attempt`` seconds\n",
    "  plus a small random jitter. On the final attempt, any error is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  url : str\n",
    "      Endpoint URL to send the GET request to.\n",
    "  params : dict, optional\n",
    "      Query string parameters to include in the request.\n",
    "  max_retries : int, default=MAX_RETRIES\n",
    "      Maximum number of retry attempts before failing.\n",
    "  timeout : int, default=REQUEST_TIMEOUT\n",
    "      Timeout in seconds for each HTTP request.\n",
    "  base_sleep : float, default=BASE_SLEEP\n",
    "      Base number of seconds used for exponential backoff between retries.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      Parsed JSON response from the server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after all retry attempts.\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns a 4xx/5xx response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * HTTP 429 triggers a wait using ``Retry-After`` if available, otherwise a fallback.\n",
    "  * Logs warnings before each retry and errors if JSON parsing fails.\n",
    "  * Uses a global ``requests.Session`` (`session`) for connection pooling.\n",
    "  \"\"\"\n",
    "\n",
    "  for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "      resp = session.get(url, params=params, timeout=timeout)\n",
    "      \n",
    "      if resp.status_code == 429:\n",
    "        retry_after = resp.headers.get('Retry-After')\n",
    "        if retry_after and retry_after.isdigit():\n",
    "          sleep_for = int(retry_after)\n",
    "        else:\n",
    "          sleep_for = max(base_sleep * attempt, 15)\n",
    "        logging.warning(f\"HTTP 429 - wait {sleep_for}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      if 500 <= resp.status_code < 600:\n",
    "        if attempt == max_retries:\n",
    "          resp.raise_for_status()\n",
    "        sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "        logging.warning(f\"HTTP {resp.status_code} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      resp.raise_for_status()\n",
    "\n",
    "      try:\n",
    "        return resp.json()\n",
    "      except json.JSONDecodeError:\n",
    "        logging.error('JSON parsing error')\n",
    "        raise\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "      if attempt == max_retries:\n",
    "        logging.exception('Request error (last attempt)')\n",
    "        raise\n",
    "      sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "      logging.warning(f\"{e} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "      time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting activities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:15,437 | INFO | Page 1: downloaded 200 records (total: 200)\n",
      "2025-09-18 14:15:21,614 | INFO | Page 2: downloaded 200 records (total: 400)\n",
      "2025-09-18 14:15:27,473 | INFO | Page 3: downloaded 200 records (total: 600)\n",
      "2025-09-18 14:15:33,898 | INFO | Page 4: downloaded 200 records (total: 800)\n",
      "2025-09-18 14:15:38,963 | INFO | Page 5: downloaded 200 records (total: 1000)\n",
      "2025-09-18 14:15:40,061 | INFO | Page 6: downloaded 94 records (total: 1094)\n",
      "2025-09-18 14:15:40,462 | INFO | Total activities downloaded: 1094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_count</th>\n",
       "      <th>total_photo_count</th>\n",
       "      <th>has_kudoed</th>\n",
       "      <th>suffer_score</th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>athlete_resource_state</th>\n",
       "      <th>map_id</th>\n",
       "      <th>map_summary_polyline</th>\n",
       "      <th>map_resource_state</th>\n",
       "      <th>average_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9km Easy RunüëΩ</td>\n",
       "      <td>9051.8</td>\n",
       "      <td>3095</td>\n",
       "      <td>3142</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15843349072</td>\n",
       "      <td>uh|vHyuogBXv@PPNDTArA[d@IB@b@p@v@zAv@hBT^HFRFr...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3825</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Workout</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15831049874</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15831049874</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tempo 2kmü•µ</td>\n",
       "      <td>9521.9</td>\n",
       "      <td>3241</td>\n",
       "      <td>3241</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15820198827</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>66.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15820198827</td>\n",
       "      <td>{_|vH{pogBx@`B\\x@HJRDN?|@Wj@GJ?\\Rt@vABRBhAD`AT...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>15km Long Run‚òîÔ∏è</td>\n",
       "      <td>15059.0</td>\n",
       "      <td>5461</td>\n",
       "      <td>5488</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15805849875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>66.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15805849875</td>\n",
       "      <td>w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Tempo 4kmüòÆ‚Äçüí®</td>\n",
       "      <td>7531.2</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15798063578</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>53.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15798063578</td>\n",
       "      <td>us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               2              9km Easy RunüëΩ    9051.8         3095   \n",
       "1               2  Afternoon Weight Training       0.0         3825   \n",
       "2               2                 Tempo 2kmü•µ    9521.9         3241   \n",
       "3               2            15km Long Run‚òîÔ∏è   15059.0         5461   \n",
       "4               2               Tempo 4kmüòÆ‚Äçüí®    7531.2         2400   \n",
       "\n",
       "   elapsed_time  total_elevation_gain     type      sport_type  workout_type  \\\n",
       "0          3142                  16.0      Run             Run           NaN   \n",
       "1          3825                   0.0  Workout  WeightTraining           NaN   \n",
       "2          3241                  13.0      Run             Run           3.0   \n",
       "3          5488                  31.0      Run             Run           2.0   \n",
       "4          2400                  11.0      Run             Run           3.0   \n",
       "\n",
       "            id  ... pr_count total_photo_count has_kudoed  suffer_score  \\\n",
       "0  15843349072  ...        0                 0      False          41.0   \n",
       "1  15831049874  ...        0                 0      False           9.0   \n",
       "2  15820198827  ...        0                 0      False          66.0   \n",
       "3  15805849875  ...        0                 0      False          66.0   \n",
       "4  15798063578  ...        0                 0      False          53.0   \n",
       "\n",
       "  athlete_id athlete_resource_state        map_id  \\\n",
       "0   81055898                      1  a15843349072   \n",
       "1   81055898                      1  a15831049874   \n",
       "2   81055898                      1  a15820198827   \n",
       "3   81055898                      1  a15805849875   \n",
       "4   81055898                      1  a15798063578   \n",
       "\n",
       "                                map_summary_polyline  map_resource_state  \\\n",
       "0  uh|vHyuogBXv@PPNDTArA[d@IB@b@p@v@zAv@hBT^HFRFr...                   2   \n",
       "1                                                                      2   \n",
       "2  {_|vH{pogBx@`B\\x@HJRDN?|@Wj@GJ?\\Rt@vABRBhAD`AT...                   2   \n",
       "3  w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...                   2   \n",
       "4  us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...                   2   \n",
       "\n",
       "   average_temp  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_all_activities(activites_url: str, per_page: int = PER_PAGE, max_pages: int = MAX_PAGES):\n",
    "  \"\"\"\n",
    "  Fetch all activity records from a paginated API endpoint.\n",
    "\n",
    "  The function iterates through API pages until either:\n",
    "    * the maximum number of pages is reached (``max_pages``), or\n",
    "    * the API returns an empty list (end of results).\n",
    "\n",
    "  Each page is retrieved using ``get_json_with_retry`` to ensure resilience\n",
    "  against transient errors (rate limits, timeouts, 5xx responses).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activites_url : str\n",
    "      The base URL of the activities endpoint (must support ``per_page`` and ``page`` query params).\n",
    "  per_page : int, default=PER_PAGE\n",
    "      Number of activity records to request per page.\n",
    "  max_pages : int, default=MAX_PAGES\n",
    "      Maximum number of pages to fetch before stopping.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  list of dict\n",
    "      Combined list of activity objects returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the API response is not a list (unexpected schema).\n",
    "  requests.exceptions.RequestException\n",
    "      If the underlying HTTP requests fail after retries.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Logs the number of records downloaded per page and the running total.\n",
    "  * Stops early if the API returns an empty list before reaching ``max_pages``.\n",
    "  * The total number of records is ``per_page * n_pages`` at most.\n",
    "  \"\"\"\n",
    "\n",
    "  all_items = []\n",
    "  page = 1\n",
    "  while page <= max_pages:\n",
    "    params = {'per_page': per_page, 'page': page}\n",
    "    data = get_json_with_retry(activites_url, params=params)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "      raise RuntimeError(f\"Unexpected response type for page {page}: {type(data)} ‚Äî expected list\")\n",
    "    \n",
    "    if not data:\n",
    "      break\n",
    "    \n",
    "    all_items.extend(data)\n",
    "    logging.info(f\"Page {page}: downloaded {len(data)} records (total: {len(all_items)})\")\n",
    "    page += 1\n",
    "  return all_items\n",
    "\n",
    "activities_raw = fetch_all_activities(ACTIVITIES_URL, per_page=PER_PAGE, max_pages=MAX_PAGES)\n",
    "logging.info(f\"Total activities downloaded: {len(activities_raw)}\")\n",
    "activities_df = pd.json_normalize(activities_raw, sep='_')\n",
    "if activities_df.empty:\n",
    "    raise RuntimeError('No activities to save.')\n",
    "activities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"average_temp\": Float,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:40,514 | WARNING | Whole table bronze.activities will be overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_full_name = f\"{TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"\n",
    "logging.warning(f\"Whole table {table_full_name} will be overwritten.\")\n",
    "activities_df.to_sql(\n",
    "  ACTIVITIES_B_TABLE, \n",
    "  engine, \n",
    "  schema=TARGET_B_SCHEMA, \n",
    "  if_exists=\"replace\", \n",
    "  index=False, \n",
    "  method=\"multi\", \n",
    "  chunksize=1000, \n",
    "  dtype=activities_dtype_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing details ‚Äî only `id` that are not present in `bronze.activities_details`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:41,440 | INFO | Missing details of 1 IDs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15843349072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "0  15843349072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE} (id BIGINT PRIMARY KEY)\n",
    "\"\"\"))\n",
    "  existing_ids = pd.read_sql(text(f\"SELECT id FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "  existing_ids_set = set(existing_ids['id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids = sorted(all_ids_set - existing_ids_set)\n",
    "logging.info(f\"Missing details of {len(missing_ids)} IDs\")\n",
    "pd.DataFrame({'id': missing_ids}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.79s/it]\n",
      "2025-09-18 14:15:49,256 | INFO | Details downloaded: 1 / 1\n"
     ]
    }
   ],
   "source": [
    "def fetch_activity_details(activity_id: int):\n",
    "  \"\"\"\n",
    "  Fetch detailed information for a single activity.\n",
    "\n",
    "  Builds the activity detail endpoint URL using the given activity ID\n",
    "  and retrieves the JSON payload with retry logic.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activity_id : int\n",
    "      Unique identifier of the activity.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      JSON object containing the activity details as returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after retries (e.g., network error, rate limit, 5xx).\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns an error response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Uses the global template ``ACTIVITY_DETAIL_URL_TMPL`` to construct the URL.\n",
    "  * Under the hood calls ``get_json_with_retry`` for resiliency.\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_DETAIL_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "details_records = []\n",
    "for i, act_id in tqdm(enumerate(missing_ids, start=1), total=len(missing_ids)):\n",
    "  try:\n",
    "    resp = fetch_activity_details(act_id)\n",
    "    \n",
    "    if not isinstance(resp, dict):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "    details_records.append(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading details for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Details downloaded: {len(details_records)} / {len(missing_ids)}\")\n",
    "details_df_new = pd.json_normalize(details_records, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_activities_max_average_speed</th>\n",
       "      <th>similar_activities_pr_rank</th>\n",
       "      <th>similar_activities_frequency_milestone</th>\n",
       "      <th>similar_activities_trend_speeds</th>\n",
       "      <th>similar_activities_trend_current_activity_index</th>\n",
       "      <th>similar_activities_trend_min_speed</th>\n",
       "      <th>similar_activities_trend_mid_speed</th>\n",
       "      <th>similar_activities_trend_max_speed</th>\n",
       "      <th>similar_activities_trend_direction</th>\n",
       "      <th>similar_activities_resource_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9km Easy RunüëΩ</td>\n",
       "      <td>9051.8</td>\n",
       "      <td>3095</td>\n",
       "      <td>3142</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>None</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944055</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[2.813875939948858, 2.819912756129609, 2.82071...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.410429</td>\n",
       "      <td>2.650651</td>\n",
       "      <td>2.944055</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state           name  distance  moving_time  elapsed_time  \\\n",
       "0               3  9km Easy RunüëΩ    9051.8         3095          3142   \n",
       "\n",
       "   total_elevation_gain type sport_type workout_type           id  ...  \\\n",
       "0                  16.0  Run        Run         None  15843349072  ...   \n",
       "\n",
       "  similar_activities_max_average_speed similar_activities_pr_rank  \\\n",
       "0                             2.944055                       None   \n",
       "\n",
       "  similar_activities_frequency_milestone  \\\n",
       "0                                   None   \n",
       "\n",
       "                     similar_activities_trend_speeds  \\\n",
       "0  [2.813875939948858, 2.819912756129609, 2.82071...   \n",
       "\n",
       "  similar_activities_trend_current_activity_index  \\\n",
       "0                                               4   \n",
       "\n",
       "  similar_activities_trend_min_speed similar_activities_trend_mid_speed  \\\n",
       "0                           2.410429                           2.650651   \n",
       "\n",
       "   similar_activities_trend_max_speed  similar_activities_trend_direction  \\\n",
       "0                            2.944055                                   1   \n",
       "\n",
       "   similar_activities_resource_state  \n",
       "0                                  2  \n",
       "\n",
       "[1 rows x 97 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not details_df_new.empty:\n",
    "  details_df_new = details_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  details_df_new = details_df_new.dropna(how='all')\n",
    "  \n",
    "details_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities_details` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_details_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"description\": Text,\n",
    "    \"calories\": Float,\n",
    "    \"perceived_exertion\": Text,\n",
    "    \"prefer_perceived_exertion\": Text,\n",
    "    \"segment_efforts\": JSONB,\n",
    "    \"splits_metric\": JSONB,\n",
    "    \"splits_standard\": JSONB,\n",
    "    \"laps\": JSONB,\n",
    "    \"best_efforts\": JSONB,\n",
    "    \"stats_visibility\": JSONB,\n",
    "    \"hide_from_home\": Boolean,\n",
    "    \"device_name\": Text,\n",
    "    \"embed_token\": Text,\n",
    "    \"available_zones\": JSONB,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"gear_primary\": Boolean,\n",
    "    \"gear_name\": Text,\n",
    "    \"gear_nickname\": Text,\n",
    "    \"gear_resource_state\": Float,\n",
    "    \"gear_retired\": Boolean,\n",
    "    \"gear_distance\": Float,\n",
    "    \"gear_converted_distance\": Float,\n",
    "    \"photos_primary\": JSONB,\n",
    "    \"photos_count\": Integer,\n",
    "    \"similar_activities_effort_count\": Float,\n",
    "    \"similar_activities_average_speed\": Float,\n",
    "    \"similar_activities_min_average_speed\": Float,\n",
    "    \"similar_activities_mid_average_speed\": Float,\n",
    "    \"similar_activities_max_average_speed\": Float,\n",
    "    \"similar_activities_pr_rank\": Float,\n",
    "    \"similar_activities_frequency_milestone\": Float,\n",
    "    \"similar_activities_trend_speeds\": JSONB,\n",
    "    \"similar_activities_trend_current_activity_index\": Float,\n",
    "    \"similar_activities_trend_min_speed\": Float,\n",
    "    \"similar_activities_trend_mid_speed\": Float,\n",
    "    \"similar_activities_trend_max_speed\": Float,\n",
    "    \"similar_activities_trend_direction\": Float,\n",
    "    \"similar_activities_resource_state\": Float,\n",
    "    \"average_temp\": Float,\n",
    "    \"photos_primary_unique_id\": Text,\n",
    "    \"photos_primary_urls_600\": Text,\n",
    "    \"photos_primary_urls_100\": Text,\n",
    "    \"photos_primary_source\": Integer,\n",
    "    \"photos_primary_media_type\": Integer,\n",
    "    \"photos_use_primary_photo\": Boolean,\n",
    "    \"private_note\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities_details` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:49,334 | INFO | Activities details saved to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "if details_df_new.empty:\n",
    "  logging.info('No new details to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    details_df_new.head(0).to_sql(\n",
    "      DETAILS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_details_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE details_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    details_df_new.to_sql(\n",
    "      \"details_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_details_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = details_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in details_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM details_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS details_stg;'))\n",
    "  \n",
    "    logging.info('Activities details saved to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:49,346 | INFO | Total number of records in bronze.activities: 1094\n",
      "2025-09-18 14:15:49,347 | INFO | Total number of records in bronze.activities_details: 1094\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    total_acts = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"), conn)\n",
    "    total_det = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}: {int(total_acts['n'][0])}\")\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}: {int(total_det['n'][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing kudos ‚Äî only `activity_id` that are not present in `bronze.kudos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 14:15:49,357 | INFO | Missing kudos of 1090 activities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15843349072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15786538213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15775473094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15766076458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15760949041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id\n",
       "0  15843349072\n",
       "1  15786538213\n",
       "2  15775473094\n",
       "3  15766076458\n",
       "4  15760949041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} (id TEXT PRIMARY KEY, activity_id BIGINT)\n",
    "\"\"\"))\n",
    "  existing_ids_kudos = pd.read_sql(text(f\"SELECT activity_id FROM {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\"), conn)\n",
    "  existing_ids_kudos_set = set(existing_ids_kudos['activity_id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_kudos_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids_kudos = sorted(all_ids_kudos_set - existing_ids_kudos_set, reverse=True)\n",
    "logging.info(f\"Missing kudos of {len(missing_ids_kudos)} activities\")\n",
    "pd.DataFrame({'activity_id': missing_ids_kudos}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities kudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 92/1090 [12:50<2:11:50,  7.93s/it]2025-09-18 14:28:40,079 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 14:28:55,475 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 14:29:11,735 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "2025-09-18 14:29:35,944 | WARNING | HTTP 429 - wait 32.0s (attempt 4/5)\n",
      " 18%|‚ñà‚ñä        | 192/1090 [28:08<2:00:21,  8.04s/it]2025-09-18 14:43:57,946 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 14:44:13,137 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 14:44:29,359 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "2025-09-18 14:44:53,589 | WARNING | HTTP 429 - wait 32.0s (attempt 4/5)\n",
      " 27%|‚ñà‚ñà‚ñã       | 292/1090 [43:28<1:52:45,  8.48s/it]2025-09-18 14:59:17,719 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 14:59:32,921 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 14:59:49,173 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 392/1090 [58:36<1:34:15,  8.10s/it]2025-09-18 15:14:26,041 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 15:14:41,256 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 15:14:57,774 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 492/1090 [1:13:18<1:18:06,  7.84s/it]2025-09-18 15:29:08,477 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 15:29:23,682 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 15:29:39,871 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 592/1090 [1:27:51<1:06:50,  8.05s/it]2025-09-18 15:43:41,404 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 15:43:56,628 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 15:44:13,321 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "2025-09-18 15:44:37,538 | WARNING | HTTP 429 - wait 32.0s (attempt 4/5)\n",
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 692/1090 [1:43:20<52:48,  7.96s/it]  2025-09-18 15:59:09,872 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 15:59:25,089 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 15:59:41,342 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 792/1090 [1:58:07<39:37,  7.98s/it]  2025-09-18 16:13:56,815 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 16:14:12,206 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 16:14:28,476 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "2025-09-18 16:14:52,781 | WARNING | HTTP 429 - wait 32.0s (attempt 4/5)\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 892/1090 [2:13:22<27:35,  8.36s/it]  2025-09-18 16:29:11,895 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 16:29:27,074 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 16:29:43,319 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 934/1090 [2:20:07<21:32,  8.29s/it]  2025-09-18 16:35:56,948 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 16:36:12,155 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 16:36:28,409 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "2025-09-18 16:36:52,696 | WARNING | HTTP 429 - wait 32.0s (attempt 4/5)\n",
      "2025-09-18 16:37:25,033 | WARNING | HTTP 429 - wait 40.0s (attempt 5/5)\n",
      "2025-09-18 16:38:05,053 | WARNING | id=6277575265: unexpected response type (<class 'NoneType'>), skip\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 935/1090 [2:22:15<1:54:29, 44.32s/it]2025-09-18 16:38:05,401 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-18 16:38:20,606 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-18 16:38:36,801 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 935/1090 [2:22:50<23:40,  9.17s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, act_id \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(missing_ids_kudos, start=\u001b[32m1\u001b[39m), total=\u001b[38;5;28mlen\u001b[39m(missing_ids_kudos)):\n\u001b[32m      9\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     resp = \u001b[43mfetch_activity_kudos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mact_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     13\u001b[39m       logging.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mact_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: unexpected response type (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(resp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m), skip\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mfetch_activity_kudos\u001b[39m\u001b[34m(activity_id)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m url = ACTIVITY_KUDOS_URL_TMPL.format(\u001b[38;5;28mid\u001b[39m=activity_id)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_json_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mget_json_with_retry\u001b[39m\u001b[34m(url, params, max_retries, timeout, base_sleep)\u001b[39m\n\u001b[32m     60\u001b[39m     sleep_for = \u001b[38;5;28mmax\u001b[39m(base_sleep * attempt, \u001b[32m15\u001b[39m)\n\u001b[32m     61\u001b[39m   logging.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHTTP 429 - wait \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msleep_for\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms (attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m   time.sleep(sleep_for)\n\u001b[32m     63\u001b[39m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m500\u001b[39m <= resp.status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def fetch_activity_kudos(activity_id: int):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_KUDOS_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "kudos_records = []\n",
    "for i, act_id in tqdm(enumerate(missing_ids_kudos, start=1), total=len(missing_ids_kudos)):\n",
    "  try:\n",
    "    resp = fetch_activity_kudos(act_id)\n",
    "    \n",
    "    if not isinstance(resp, list):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "\n",
    "    for i, kudos in enumerate(resp):\n",
    "      kudos[\"activity_id\"] = act_id\n",
    "      kudos[\"kudos_id\"] = i\n",
    "    kudos_records.extend(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading kudos for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Kudos downloaded: {len(kudos_records)} / {len(missing_ids_kudos)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kudos_df_new = pd.json_normalize(kudos_records, sep='_')\n",
    "if not kudos_df_new.empty:\n",
    "  kudos_df_new = kudos_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  kudos_df_new = kudos_df_new.dropna(how='all')\n",
    "  \n",
    "kudos_df_new['id'] = kudos_df_new[['activity_id', 'kudos_id']].astype(\"string\").agg(\"-\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>kudos_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Adam</td>\n",
       "      <td>K.</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>0</td>\n",
       "      <td>15843349072-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jakub</td>\n",
       "      <td>≈Å.</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>1</td>\n",
       "      <td>15843349072-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wies≈Çawa</td>\n",
       "      <td>C.</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>2</td>\n",
       "      <td>15843349072-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Mal</td>\n",
       "      <td>C.</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>3</td>\n",
       "      <td>15843349072-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Karolina</td>\n",
       "      <td>C.</td>\n",
       "      <td>15843349072</td>\n",
       "      <td>4</td>\n",
       "      <td>15843349072-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state firstname lastname  activity_id  kudos_id             id\n",
       "0               2      Adam       K.  15843349072         0  15843349072-0\n",
       "1               2     Jakub       ≈Å.  15843349072         1  15843349072-1\n",
       "2               2  Wies≈Çawa       C.  15843349072         2  15843349072-2\n",
       "3               2       Mal       C.  15843349072         3  15843349072-3\n",
       "4               2  Karolina       C.  15843349072         4  15843349072-4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kudos_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.kudos` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_kudos_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"first_name\": Text,\n",
    "    \"last_name\": Float,\n",
    "    \"activity_id\": BigInteger,\n",
    "    \"id\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.kudos` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-18 16:39:06,229 | INFO | Activities kudos saved to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "if kudos_df_new.empty:\n",
    "  logging.info('No new kudos to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=KUDOS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    kudos_df_new.head(0).to_sql(\n",
    "      KUDOS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_kudos_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=KUDOS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE kudos_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    kudos_df_new.to_sql(\n",
    "      \"kudos_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_kudos_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = kudos_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in kudos_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM kudos_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS kudos_stg;'))\n",
    "  \n",
    "    logging.info('Activities kudos saved to PostgreSQL.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strava-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
