{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, text, inspect, Text, Integer, BigInteger, Float, Boolean\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "# API urls\n",
    "AUTH_URL = os.getenv('AUTH_URL')\n",
    "ACTIVITIES_URL = os.getenv('ACTIVITIES_URL')\n",
    "ACTIVITY_DETAIL_URL_TMPL = os.getenv('ACTIVITY_DETAIL_URL_TMPL')\n",
    "\n",
    "# API keys\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')\n",
    "\n",
    "# DB\n",
    "DB_URI = os.getenv('DB_URI')\n",
    "\n",
    "# Bronze tables\n",
    "TARGET_B_SCHEMA = os.getenv('TARGET_B_SCHEMA')\n",
    "ACTIVITIES_B_TABLE = os.getenv('ACTIVITIES_B_TABLE')\n",
    "DETAILS_B_TABLE = os.getenv('DETAILS_B_TABLE')\n",
    "\n",
    "# Pagination\n",
    "PER_PAGE = int(os.getenv('PER_PAGE'))\n",
    "MAX_PAGES = int(os.getenv('MAX_PAGES'))\n",
    "\n",
    "# Timeouts and retries\n",
    "REQUEST_TIMEOUT = int(os.getenv('REQUEST_TIMEOUT'))\n",
    "MAX_RETRIES = int(os.getenv('MAX_RETRIES'))\n",
    "BASE_SLEEP = float(os.getenv('BASE_SLEEP'))\n",
    "\n",
    "# Other\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL.upper(), logging.INFO),\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_API_ENV = ['CLIENT_ID', 'CLIENT_SECRET', 'REFRESH_TOKEN']\n",
    "missing_api_env = [env for env in REQUIRED_API_ENV if not os.getenv(env)]\n",
    "if missing_api_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_api_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB names validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_DB_ENV = ['DB_URI', 'TARGET_B_SCHEMA', 'ACTIVITIES_B_TABLE', 'DETAILS_B_TABLE']\n",
    "missing_db_env = [env for env in REQUIRED_DB_ENV if not os.getenv(env)]\n",
    "if missing_db_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_db_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:12:43,980 | INFO | Connection established and bronze schema exists.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "  DB_URI, \n",
    "  pool_pre_ping=True, \n",
    "  pool_size=5, \n",
    "  max_overflow=10\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "  conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_B_SCHEMA};\"))\n",
    "logging.info(f\"Connection established and {TARGET_B_SCHEMA} schema exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 12:51:19,533 | INFO | Access token retrived.\n"
     ]
    }
   ],
   "source": [
    "def get_access_token(auth_url: str, client_id: str, client_secret: str, refresh_token: str, timeout: int = 30) -> str:\n",
    "  \"\"\"\n",
    "  Request a new access token from an OAuth2 authentication endpoint.\n",
    "\n",
    "  The function uses a refresh token to obtain a short-lived access token. \n",
    "  If the response does not contain an ``access_token``, a RuntimeError is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  auth_url : str\n",
    "      URL of the OAuth2 token endpoint.\n",
    "  client_id : str\n",
    "      OAuth2 client identifier.\n",
    "  client_secret : str\n",
    "      OAuth2 client secret.\n",
    "  refresh_token : str\n",
    "      Refresh token used to request a new access token.\n",
    "  timeout : int, default=30\n",
    "      Timeout in seconds for the HTTP request.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  str\n",
    "      The access token string retrieved from the authentication server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the response does not include an ``access_token``.\n",
    "  requests.exceptions.RequestException\n",
    "      If the HTTP request fails (e.g., network error, timeout).\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  Logs an informational message when the token is successfully retrieved.\n",
    "  \"\"\"\n",
    "\n",
    "  payload = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'refresh_token': refresh_token,\n",
    "    'grant_type': 'refresh_token',\n",
    "  }\n",
    "  res = requests.post(auth_url, data=payload, timeout=timeout)\n",
    "  data = res.json()\n",
    "  token = data.get('access_token')\n",
    "  if not token:\n",
    "    raise RuntimeError(f\"No access token in response: {data}\")\n",
    "  logging.info('Access token retrived.')\n",
    "  return token\n",
    "\n",
    "access_token = get_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"Authorization\": f\"Bearer {access_token}\"})\n",
    "\n",
    "def get_json_with_retry(url: str, params=None, max_retries: int = MAX_RETRIES, timeout: int = REQUEST_TIMEOUT, base_sleep: float = BASE_SLEEP):\n",
    "  \"\"\"\n",
    "  Send a GET request with automatic retries and return the parsed JSON response.\n",
    "\n",
    "  The function retries on:\n",
    "    * HTTP 429 (rate limiting) ‚Äî respects the ``Retry-After`` header if present,\n",
    "      otherwise waits an increasing backoff time.\n",
    "    * HTTP 5xx errors ‚Äî retries with exponential backoff and jitter.\n",
    "    * Network/connection errors ‚Äî retries with exponential backoff and jitter.\n",
    "\n",
    "  For each attempt, the backoff time increases by ``base_sleep * attempt`` seconds\n",
    "  plus a small random jitter. On the final attempt, any error is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  url : str\n",
    "      Endpoint URL to send the GET request to.\n",
    "  params : dict, optional\n",
    "      Query string parameters to include in the request.\n",
    "  max_retries : int, default=MAX_RETRIES\n",
    "      Maximum number of retry attempts before failing.\n",
    "  timeout : int, default=REQUEST_TIMEOUT\n",
    "      Timeout in seconds for each HTTP request.\n",
    "  base_sleep : float, default=BASE_SLEEP\n",
    "      Base number of seconds used for exponential backoff between retries.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      Parsed JSON response from the server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after all retry attempts.\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns a 4xx/5xx response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * HTTP 429 triggers a wait using ``Retry-After`` if available, otherwise a fallback.\n",
    "  * Logs warnings before each retry and errors if JSON parsing fails.\n",
    "  * Uses a global ``requests.Session`` (`session`) for connection pooling.\n",
    "  \"\"\"\n",
    "\n",
    "  for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "      resp = session.get(url, params=params, timeout=timeout)\n",
    "      \n",
    "      if resp.status_code == 429:\n",
    "        retry_after = resp.headers.get('Retry-After')\n",
    "        if retry_after and retry_after.isdigit():\n",
    "          sleep_for = int(retry_after)\n",
    "        else:\n",
    "          sleep_for = max(base_sleep * attempt, 15)\n",
    "        logging.warning(f\"HTTP 429 - wait {sleep_for}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      if 500 <= resp.status_code < 600:\n",
    "        if attempt == max_retries:\n",
    "          resp.raise_for_status()\n",
    "        sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "        logging.warning(f\"HTTP {resp.status_code} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      resp.raise_for_status()\n",
    "\n",
    "      try:\n",
    "        return resp.json()\n",
    "      except json.JSONDecodeError:\n",
    "        logging.error('JSON parsing error')\n",
    "        raise\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "      if attempt == max_retries:\n",
    "        logging.exception('Request error (last attempt)')\n",
    "        raise\n",
    "      sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "      logging.warning(f\"{e} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "      time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting activities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:12:49,275 | INFO | Page 1: downloaded 200 records (total: 200)\n",
      "2025-09-16 19:12:53,228 | INFO | Page 2: downloaded 200 records (total: 400)\n",
      "2025-09-16 19:12:57,582 | INFO | Page 3: downloaded 200 records (total: 600)\n",
      "2025-09-16 19:13:00,824 | INFO | Page 4: downloaded 200 records (total: 800)\n",
      "2025-09-16 19:13:04,634 | INFO | Page 5: downloaded 200 records (total: 1000)\n",
      "2025-09-16 19:13:05,291 | INFO | Page 6: downloaded 93 records (total: 1093)\n",
      "2025-09-16 19:13:05,483 | INFO | Total activities downloaded: 1093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>...</th>\n",
       "      <th>map_summary_polyline</th>\n",
       "      <th>map_resource_state</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>average_cadence</th>\n",
       "      <th>average_watts</th>\n",
       "      <th>max_watts</th>\n",
       "      <th>weighted_average_watts</th>\n",
       "      <th>device_watts</th>\n",
       "      <th>kilojoules</th>\n",
       "      <th>average_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3825</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Workout</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>15831049874</td>\n",
       "      <td>2025-09-16T13:01:07Z</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tempo 2kmü•µ</td>\n",
       "      <td>9521.9</td>\n",
       "      <td>3241</td>\n",
       "      <td>3241</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>15820198827</td>\n",
       "      <td>2025-09-15T14:23:21Z</td>\n",
       "      <td>...</td>\n",
       "      <td>{_|vH{pogBx@`B\\x@HJRDN?|@Wj@GJ?\\Rt@vABRBhAD`AT...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>353.5</td>\n",
       "      <td>493.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15km Long Run‚òîÔ∏è</td>\n",
       "      <td>15059.0</td>\n",
       "      <td>5461</td>\n",
       "      <td>5488</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>15805849875</td>\n",
       "      <td>2025-09-14T07:59:25Z</td>\n",
       "      <td>...</td>\n",
       "      <td>w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>335.5</td>\n",
       "      <td>455.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Tempo 4kmüòÆ‚Äçüí®</td>\n",
       "      <td>7531.2</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>15798063578</td>\n",
       "      <td>2025-09-13T13:59:16Z</td>\n",
       "      <td>...</td>\n",
       "      <td>us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>364.2</td>\n",
       "      <td>509.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>True</td>\n",
       "      <td>873.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6km Easy Runüòå</td>\n",
       "      <td>6062.9</td>\n",
       "      <td>2140</td>\n",
       "      <td>2140</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>15786538213</td>\n",
       "      <td>2025-09-12T13:40:46Z</td>\n",
       "      <td>...</td>\n",
       "      <td>kh|vHguogBJ\\JNHFRBN?fBc@\\FZ`@JXdAzBp@xAHFRBNAh...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.1</td>\n",
       "      <td>351.5</td>\n",
       "      <td>445.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>True</td>\n",
       "      <td>752.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               2  Afternoon Weight Training       0.0         3825   \n",
       "1               2                 Tempo 2kmü•µ    9521.9         3241   \n",
       "2               2            15km Long Run‚òîÔ∏è   15059.0         5461   \n",
       "3               2               Tempo 4kmüòÆ‚Äçüí®    7531.2         2400   \n",
       "4               2              6km Easy Runüòå    6062.9         2140   \n",
       "\n",
       "   elapsed_time  total_elevation_gain     type      sport_type           id  \\\n",
       "0          3825                   0.0  Workout  WeightTraining  15831049874   \n",
       "1          3241                  13.0      Run             Run  15820198827   \n",
       "2          5488                  31.0      Run             Run  15805849875   \n",
       "3          2400                  11.0      Run             Run  15798063578   \n",
       "4          2140                  17.0      Run             Run  15786538213   \n",
       "\n",
       "             start_date  ...  \\\n",
       "0  2025-09-16T13:01:07Z  ...   \n",
       "1  2025-09-15T14:23:21Z  ...   \n",
       "2  2025-09-14T07:59:25Z  ...   \n",
       "3  2025-09-13T13:59:16Z  ...   \n",
       "4  2025-09-12T13:40:46Z  ...   \n",
       "\n",
       "                                map_summary_polyline map_resource_state  \\\n",
       "0                                                                     2   \n",
       "1  {_|vH{pogBx@`B\\x@HJRDN?|@Wj@GJ?\\Rt@vABRBhAD`AT...                  2   \n",
       "2  w_|vHqpogBrAnCNj@@l@Gb@o@hAa@h@QXuCpDyDbEsApAk...                  2   \n",
       "3  us{vHm~ngBJ`@P`@Nt@\\b@j@`BXj@`@bAf@|ATz@j@xDJ`...                  2   \n",
       "4  kh|vHguogBJ\\JNHFRBN?fBc@\\FZ`@JXdAzBp@xAHFRBNAh...                  2   \n",
       "\n",
       "   workout_type average_cadence average_watts max_watts  \\\n",
       "0           NaN             NaN           NaN       NaN   \n",
       "1           3.0            83.9         353.5     493.0   \n",
       "2           2.0            86.0         335.5     455.0   \n",
       "3           3.0            83.9         364.2     509.0   \n",
       "4           NaN            83.1         351.5     445.0   \n",
       "\n",
       "   weighted_average_watts  device_watts  kilojoules  average_temp  \n",
       "0                     NaN           NaN         NaN           NaN  \n",
       "1                   369.0          True      1144.0           NaN  \n",
       "2                   334.0          True      1833.0           NaN  \n",
       "3                   377.0          True       873.1           NaN  \n",
       "4                   350.0          True       752.4           NaN  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_all_activities(activites_url: str, per_page: int = PER_PAGE, max_pages: int = MAX_PAGES):\n",
    "  \"\"\"\n",
    "  Fetch all activity records from a paginated API endpoint.\n",
    "\n",
    "  The function iterates through API pages until either:\n",
    "    * the maximum number of pages is reached (``max_pages``), or\n",
    "    * the API returns an empty list (end of results).\n",
    "\n",
    "  Each page is retrieved using ``get_json_with_retry`` to ensure resilience\n",
    "  against transient errors (rate limits, timeouts, 5xx responses).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activites_url : str\n",
    "      The base URL of the activities endpoint (must support ``per_page`` and ``page`` query params).\n",
    "  per_page : int, default=PER_PAGE\n",
    "      Number of activity records to request per page.\n",
    "  max_pages : int, default=MAX_PAGES\n",
    "      Maximum number of pages to fetch before stopping.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  list of dict\n",
    "      Combined list of activity objects returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the API response is not a list (unexpected schema).\n",
    "  requests.exceptions.RequestException\n",
    "      If the underlying HTTP requests fail after retries.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Logs the number of records downloaded per page and the running total.\n",
    "  * Stops early if the API returns an empty list before reaching ``max_pages``.\n",
    "  * The total number of records is ``per_page * n_pages`` at most.\n",
    "  \"\"\"\n",
    "\n",
    "  all_items = []\n",
    "  page = 1\n",
    "  while page <= max_pages:\n",
    "    params = {'per_page': per_page, 'page': page}\n",
    "    data = get_json_with_retry(activites_url, params=params)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "      raise RuntimeError(f\"Unexpected response type for page {page}: {type(data)} ‚Äî expected list\")\n",
    "    \n",
    "    if not data:\n",
    "      break\n",
    "    \n",
    "    all_items.extend(data)\n",
    "    logging.info(f\"Page {page}: downloaded {len(data)} records (total: {len(all_items)})\")\n",
    "    page += 1\n",
    "  return all_items\n",
    "\n",
    "activities_raw = fetch_all_activities(ACTIVITIES_URL, per_page=PER_PAGE, max_pages=MAX_PAGES)\n",
    "logging.info(f\"Total activities downloaded: {len(activities_raw)}\")\n",
    "activities_df = pd.json_normalize(activities_raw, sep='_')\n",
    "if activities_df.empty:\n",
    "    raise RuntimeError('No activities to save.')\n",
    "activities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"average_temp\": Float,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:13:05,531 | WARNING | Whole table bronze.activities will be overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_full_name = f\"{TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"\n",
    "logging.warning(f\"Whole table {table_full_name} will be overwritten.\")\n",
    "activities_df.to_sql(\n",
    "  ACTIVITIES_B_TABLE, \n",
    "  engine, \n",
    "  schema=TARGET_B_SCHEMA, \n",
    "  if_exists=\"replace\", \n",
    "  index=False, \n",
    "  method=\"multi\", \n",
    "  chunksize=1000, \n",
    "  dtype=activities_dtype_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing details ‚Äî only `id` that are not present in `bronze.activities_details`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:13:06,402 | INFO | Missing details of 2 IDs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15820198827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15831049874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "0  15820198827\n",
       "1  15831049874"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE} (id BIGINT PRIMARY KEY)\n",
    "\"\"\"))\n",
    "  existing_ids = pd.read_sql(text(f\"SELECT id FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "  existing_ids_set = set(existing_ids['id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids = sorted(all_ids_set - existing_ids_set)\n",
    "logging.info(f\"Missing details of {len(missing_ids)} IDs\")\n",
    "pd.DataFrame({'id': missing_ids}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:19<00:00,  9.50s/it]\n",
      "2025-09-16 19:13:25,435 | INFO | Details downloaded: 2 / 2\n"
     ]
    }
   ],
   "source": [
    "def fetch_activity_details(activity_id: int):\n",
    "  \"\"\"\n",
    "  Fetch detailed information for a single activity.\n",
    "\n",
    "  Builds the activity detail endpoint URL using the given activity ID\n",
    "  and retrieves the JSON payload with retry logic.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activity_id : int\n",
    "      Unique identifier of the activity.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      JSON object containing the activity details as returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after retries (e.g., network error, rate limit, 5xx).\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns an error response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Uses the global template ``ACTIVITY_DETAIL_URL_TMPL`` to construct the URL.\n",
    "  * Under the hood calls ``get_json_with_retry`` for resiliency.\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_DETAIL_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "details_records = []\n",
    "for i, act_id in tqdm(enumerate(missing_ids, start=1), total=len(missing_ids)):\n",
    "  try:\n",
    "    resp = fetch_activity_details(act_id)\n",
    "    \n",
    "    if not isinstance(resp, dict):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "    details_records.append(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading details for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Details downloaded: {len(details_records)} / {len(missing_ids)}\")\n",
    "details_df_new = pd.json_normalize(details_records, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_activities_max_average_speed</th>\n",
       "      <th>similar_activities_pr_rank</th>\n",
       "      <th>similar_activities_frequency_milestone</th>\n",
       "      <th>similar_activities_trend_speeds</th>\n",
       "      <th>similar_activities_trend_current_activity_index</th>\n",
       "      <th>similar_activities_trend_min_speed</th>\n",
       "      <th>similar_activities_trend_mid_speed</th>\n",
       "      <th>similar_activities_trend_max_speed</th>\n",
       "      <th>similar_activities_trend_direction</th>\n",
       "      <th>similar_activities_resource_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Tempo 2kmü•µ</td>\n",
       "      <td>9521.9</td>\n",
       "      <td>3241</td>\n",
       "      <td>3241</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15820198827</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944055</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2.8269134384090804, 2.813875939948858, 2.8199...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.410429</td>\n",
       "      <td>2.650651</td>\n",
       "      <td>2.944055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3825</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Workout</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15831049874</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               3                 Tempo 2kmü•µ    9521.9         3241   \n",
       "1               3  Afternoon Weight Training       0.0         3825   \n",
       "\n",
       "   elapsed_time  total_elevation_gain     type      sport_type  workout_type  \\\n",
       "0          3241                  13.0      Run             Run           3.0   \n",
       "1          3825                   0.0  Workout  WeightTraining           NaN   \n",
       "\n",
       "            id  ... similar_activities_max_average_speed  \\\n",
       "0  15820198827  ...                             2.944055   \n",
       "1  15831049874  ...                                  NaN   \n",
       "\n",
       "  similar_activities_pr_rank similar_activities_frequency_milestone  \\\n",
       "0                        3.0                                    NaN   \n",
       "1                        NaN                                    NaN   \n",
       "\n",
       "                     similar_activities_trend_speeds  \\\n",
       "0  [2.8269134384090804, 2.813875939948858, 2.8199...   \n",
       "1                                                NaN   \n",
       "\n",
       "  similar_activities_trend_current_activity_index  \\\n",
       "0                                             4.0   \n",
       "1                                             NaN   \n",
       "\n",
       "  similar_activities_trend_min_speed similar_activities_trend_mid_speed  \\\n",
       "0                           2.410429                           2.650651   \n",
       "1                                NaN                                NaN   \n",
       "\n",
       "   similar_activities_trend_max_speed  similar_activities_trend_direction  \\\n",
       "0                            2.944055                                 1.0   \n",
       "1                                 NaN                                 NaN   \n",
       "\n",
       "   similar_activities_resource_state  \n",
       "0                                2.0  \n",
       "1                                NaN  \n",
       "\n",
       "[2 rows x 97 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not details_df_new.empty:\n",
    "  details_df_new = details_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  details_df_new = details_df_new.dropna(how='all')\n",
    "  \n",
    "details_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities_details` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_details_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"description\": Text,\n",
    "    \"calories\": Float,\n",
    "    \"perceived_exertion\": Text,\n",
    "    \"prefer_perceived_exertion\": Text,\n",
    "    \"segment_efforts\": JSONB,\n",
    "    \"splits_metric\": JSONB,\n",
    "    \"splits_standard\": JSONB,\n",
    "    \"laps\": JSONB,\n",
    "    \"best_efforts\": JSONB,\n",
    "    \"stats_visibility\": JSONB,\n",
    "    \"hide_from_home\": Boolean,\n",
    "    \"device_name\": Text,\n",
    "    \"embed_token\": Text,\n",
    "    \"available_zones\": JSONB,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"gear_primary\": Boolean,\n",
    "    \"gear_name\": Text,\n",
    "    \"gear_nickname\": Text,\n",
    "    \"gear_resource_state\": Float,\n",
    "    \"gear_retired\": Boolean,\n",
    "    \"gear_distance\": Float,\n",
    "    \"gear_converted_distance\": Float,\n",
    "    \"photos_primary\": JSONB,\n",
    "    \"photos_count\": Integer,\n",
    "    \"similar_activities_effort_count\": Float,\n",
    "    \"similar_activities_average_speed\": Float,\n",
    "    \"similar_activities_min_average_speed\": Float,\n",
    "    \"similar_activities_mid_average_speed\": Float,\n",
    "    \"similar_activities_max_average_speed\": Float,\n",
    "    \"similar_activities_pr_rank\": Float,\n",
    "    \"similar_activities_frequency_milestone\": Float,\n",
    "    \"similar_activities_trend_speeds\": JSONB,\n",
    "    \"similar_activities_trend_current_activity_index\": Float,\n",
    "    \"similar_activities_trend_min_speed\": Float,\n",
    "    \"similar_activities_trend_mid_speed\": Float,\n",
    "    \"similar_activities_trend_max_speed\": Float,\n",
    "    \"similar_activities_trend_direction\": Float,\n",
    "    \"similar_activities_resource_state\": Float,\n",
    "    \"average_temp\": Float,\n",
    "    \"photos_primary_unique_id\": Text,\n",
    "    \"photos_primary_urls_600\": Text,\n",
    "    \"photos_primary_urls_100\": Text,\n",
    "    \"photos_primary_source\": Integer,\n",
    "    \"photos_primary_media_type\": Integer,\n",
    "    \"photos_use_primary_photo\": Boolean,\n",
    "    \"private_note\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities_details` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:13:25,508 | INFO | Activities details saved to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "if details_df_new.empty:\n",
    "  logging.info('No new details to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    details_df_new[0].to_sql(\n",
    "      DETAILS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_details_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE details_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    details_df_new.to_sql(\n",
    "      \"details_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_details_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = details_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in details_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM details_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS details_stg;'))\n",
    "  \n",
    "    logging.info('Activities details saved to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-16 19:13:25,526 | INFO | Total number of records in bronze.activities: 1093\n",
      "2025-09-16 19:13:25,527 | INFO | Total number of records in bronze.activities_details: 1093\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    total_acts = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"), conn)\n",
    "    total_det = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}: {int(total_acts['n'][0])}\")\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}: {int(total_det['n'][0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strava-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
