{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sqlalchemy import create_engine, text, inspect, Text, Integer, BigInteger, Float, Boolean\n",
    "from sqlalchemy.dialects.postgresql import JSONB\n",
    "\n",
    "# Configuration\n",
    "load_dotenv()\n",
    "\n",
    "# API urls\n",
    "AUTH_URL = os.getenv('AUTH_URL')\n",
    "ACTIVITIES_URL = os.getenv('ACTIVITIES_URL')\n",
    "ACTIVITY_DETAIL_URL_TMPL = os.getenv('ACTIVITY_DETAIL_URL_TMPL')\n",
    "ACTIVITY_KUDOS_URL_TMPL = os.getenv('ACTIVITY_KUDOS_URL_TMPL')\n",
    "\n",
    "# API keys\n",
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET')\n",
    "REFRESH_TOKEN = os.getenv('REFRESH_TOKEN')\n",
    "\n",
    "# DB\n",
    "DB_URI = os.getenv('DB_URI')\n",
    "\n",
    "# Bronze tables\n",
    "TARGET_B_SCHEMA = os.getenv('TARGET_B_SCHEMA')\n",
    "ACTIVITIES_B_TABLE = os.getenv('ACTIVITIES_B_TABLE')\n",
    "DETAILS_B_TABLE = os.getenv('DETAILS_B_TABLE')\n",
    "KUDOS_B_TABLE = os.getenv('KUDOS_B_TABLE')\n",
    "\n",
    "# Pagination\n",
    "PER_PAGE = int(os.getenv('PER_PAGE'))\n",
    "MAX_PAGES = int(os.getenv('MAX_PAGES'))\n",
    "\n",
    "# Timeouts and retries\n",
    "REQUEST_TIMEOUT = int(os.getenv('REQUEST_TIMEOUT'))\n",
    "MAX_RETRIES = int(os.getenv('MAX_RETRIES'))\n",
    "BASE_SLEEP = float(os.getenv('BASE_SLEEP'))\n",
    "\n",
    "REFRESH_THRESHOLD_DAYS = int(os.getenv('REFRESH_THRESHOLD_DAYS'))\n",
    "\n",
    "# Other\n",
    "LOG_LEVEL = os.getenv('LOG_LEVEL')\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, LOG_LEVEL.upper(), logging.INFO),\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API keys validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_API_ENV = ['CLIENT_ID', 'CLIENT_SECRET', 'REFRESH_TOKEN']\n",
    "missing_api_env = [env for env in REQUIRED_API_ENV if not os.getenv(env)]\n",
    "if missing_api_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_api_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB names validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIRED_DB_ENV = ['DB_URI', 'TARGET_B_SCHEMA', 'ACTIVITIES_B_TABLE', 'DETAILS_B_TABLE']\n",
    "missing_db_env = [env for env in REQUIRED_DB_ENV if not os.getenv(env)]\n",
    "if missing_db_env:\n",
    "  raise RuntimeError(f\"Missing env variables: {', '.join(missing_db_env)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting with PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:28:44,657 | INFO | Connection established and bronze schema exists.\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine(\n",
    "  DB_URI, \n",
    "  pool_pre_ping=True, \n",
    "  pool_size=5, \n",
    "  max_overflow=10\n",
    ")\n",
    "with engine.connect() as conn:\n",
    "  conn.execute(text(f\"CREATE SCHEMA IF NOT EXISTS {TARGET_B_SCHEMA};\"))\n",
    "logging.info(f\"Connection established and {TARGET_B_SCHEMA} schema exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:28:45,065 | INFO | Access token retrived.\n"
     ]
    }
   ],
   "source": [
    "def get_access_token(auth_url: str, client_id: str, client_secret: str, refresh_token: str, timeout: int = 30) -> str:\n",
    "  \"\"\"\n",
    "  Request a new access token from an OAuth2 authentication endpoint.\n",
    "\n",
    "  The function uses a refresh token to obtain a short-lived access token. \n",
    "  If the response does not contain an ``access_token``, a RuntimeError is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  auth_url : str\n",
    "      URL of the OAuth2 token endpoint.\n",
    "  client_id : str\n",
    "      OAuth2 client identifier.\n",
    "  client_secret : str\n",
    "      OAuth2 client secret.\n",
    "  refresh_token : str\n",
    "      Refresh token used to request a new access token.\n",
    "  timeout : int, default=30\n",
    "      Timeout in seconds for the HTTP request.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  str\n",
    "      The access token string retrieved from the authentication server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the response does not include an ``access_token``.\n",
    "  requests.exceptions.RequestException\n",
    "      If the HTTP request fails (e.g., network error, timeout).\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  Logs an informational message when the token is successfully retrieved.\n",
    "  \"\"\"\n",
    "\n",
    "  payload = {\n",
    "    'client_id': client_id,\n",
    "    'client_secret': client_secret,\n",
    "    'refresh_token': refresh_token,\n",
    "    'grant_type': 'refresh_token',\n",
    "  }\n",
    "  res = requests.post(auth_url, data=payload, timeout=timeout)\n",
    "  data = res.json()\n",
    "  token = data.get('access_token')\n",
    "  if not token:\n",
    "    raise RuntimeError(f\"No access token in response: {data}\")\n",
    "  logging.info('Access token retrived.')\n",
    "  return token\n",
    "\n",
    "access_token = get_access_token(AUTH_URL, CLIENT_ID, CLIENT_SECRET, REFRESH_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers.update({\"Authorization\": f\"Bearer {access_token}\"})\n",
    "\n",
    "def get_json_with_retry(url: str, params=None, max_retries: int = MAX_RETRIES, timeout: int = REQUEST_TIMEOUT, base_sleep: float = BASE_SLEEP):\n",
    "  \"\"\"\n",
    "  Send a GET request with automatic retries and return the parsed JSON response.\n",
    "\n",
    "  The function retries on:\n",
    "    * HTTP 429 (rate limiting) ‚Äî respects the ``Retry-After`` header if present,\n",
    "      otherwise waits an increasing backoff time.\n",
    "    * HTTP 5xx errors ‚Äî retries with exponential backoff and jitter.\n",
    "    * Network/connection errors ‚Äî retries with exponential backoff and jitter.\n",
    "\n",
    "  For each attempt, the backoff time increases by ``base_sleep * attempt`` seconds\n",
    "  plus a small random jitter. On the final attempt, any error is raised.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  url : str\n",
    "      Endpoint URL to send the GET request to.\n",
    "  params : dict, optional\n",
    "      Query string parameters to include in the request.\n",
    "  max_retries : int, default=MAX_RETRIES\n",
    "      Maximum number of retry attempts before failing.\n",
    "  timeout : int, default=REQUEST_TIMEOUT\n",
    "      Timeout in seconds for each HTTP request.\n",
    "  base_sleep : float, default=BASE_SLEEP\n",
    "      Base number of seconds used for exponential backoff between retries.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      Parsed JSON response from the server.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after all retry attempts.\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns a 4xx/5xx response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * HTTP 429 triggers a wait using ``Retry-After`` if available, otherwise a fallback.\n",
    "  * Logs warnings before each retry and errors if JSON parsing fails.\n",
    "  * Uses a global ``requests.Session`` (`session`) for connection pooling.\n",
    "  \"\"\"\n",
    "\n",
    "  for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "      resp = session.get(url, params=params, timeout=timeout)\n",
    "      \n",
    "      if resp.status_code == 429:\n",
    "        retry_after = resp.headers.get('Retry-After')\n",
    "        if retry_after and retry_after.isdigit():\n",
    "          sleep_for = int(retry_after)\n",
    "        else:\n",
    "          sleep_for = max(base_sleep * attempt, 15)\n",
    "        logging.warning(f\"HTTP 429 - wait {sleep_for}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      if 500 <= resp.status_code < 600:\n",
    "        if attempt == max_retries:\n",
    "          resp.raise_for_status()\n",
    "        sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "        logging.warning(f\"HTTP {resp.status_code} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "        time.sleep(sleep_for)\n",
    "        continue\n",
    "\n",
    "      resp.raise_for_status()\n",
    "\n",
    "      try:\n",
    "        return resp.json()\n",
    "      except json.JSONDecodeError:\n",
    "        logging.error('JSON parsing error')\n",
    "        raise\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "      if attempt == max_retries:\n",
    "        logging.exception('Request error (last attempt)')\n",
    "        raise\n",
    "      sleep_for = base_sleep * attempt + random.uniform(0, 1.0)\n",
    "      logging.warning(f\"{e} ‚Äî retry in {sleep_for:.1f}s (attempt {attempt}/{max_retries})\")\n",
    "      time.sleep(sleep_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting activities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:28:50,086 | INFO | Page 1: downloaded 200 records (total: 200)\n",
      "2025-09-23 12:28:56,495 | INFO | Page 2: downloaded 200 records (total: 400)\n",
      "2025-09-23 12:29:03,494 | INFO | Page 3: downloaded 200 records (total: 600)\n",
      "2025-09-23 12:29:10,084 | INFO | Page 4: downloaded 200 records (total: 800)\n",
      "2025-09-23 12:29:14,891 | INFO | Page 5: downloaded 200 records (total: 1000)\n",
      "2025-09-23 12:29:15,998 | INFO | Page 6: downloaded 99 records (total: 1099)\n",
      "2025-09-23 12:29:16,228 | INFO | Total activities downloaded: 1099\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>has_kudoed</th>\n",
       "      <th>suffer_score</th>\n",
       "      <th>athlete_id</th>\n",
       "      <th>athlete_resource_state</th>\n",
       "      <th>map_id</th>\n",
       "      <th>map_summary_polyline</th>\n",
       "      <th>map_resource_state</th>\n",
       "      <th>average_cadence</th>\n",
       "      <th>max_watts</th>\n",
       "      <th>weighted_average_watts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Afternoon Ride</td>\n",
       "      <td>23312.2</td>\n",
       "      <td>5551</td>\n",
       "      <td>8140</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Ride</td>\n",
       "      <td>Ride</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15891685827</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>11.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15891685827</td>\n",
       "      <td>ki}vHuomgBcDnFgCtEsAdBi@z@aInNWh@KvAKZQP_@B{@f...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>23km Long Runü•µ</td>\n",
       "      <td>20049.3</td>\n",
       "      <td>7499</td>\n",
       "      <td>8179</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15885021588</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>98.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15885021588</td>\n",
       "      <td>wf}vHismgBkArBaAvAWh@g@x@q@bA{AzCi@|@gApAgEpHe...</td>\n",
       "      <td>2</td>\n",
       "      <td>83.7</td>\n",
       "      <td>499.0</td>\n",
       "      <td>323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Evening Ride</td>\n",
       "      <td>19347.2</td>\n",
       "      <td>4273</td>\n",
       "      <td>4375</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Ride</td>\n",
       "      <td>Ride</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15879687027</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15879687027</td>\n",
       "      <td>oh|vHsuogBVn@XNDNAFiBjDy@hAi@f@qAxBcAvAgAdBSN[...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3673</td>\n",
       "      <td>3673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Workout</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15865360447</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15865360447</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>K200süèéÔ∏è</td>\n",
       "      <td>9915.6</td>\n",
       "      <td>3272</td>\n",
       "      <td>3314</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15855640218</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>60.0</td>\n",
       "      <td>81055898</td>\n",
       "      <td>1</td>\n",
       "      <td>a15855640218</td>\n",
       "      <td>or{vHq{ngBHZ^l@Vv@|@rB|@nCd@rCf@rDZtApAjEdBjF^...</td>\n",
       "      <td>2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>546.0</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               2             Afternoon Ride   23312.2         5551   \n",
       "1               2             23km Long Runü•µ   20049.3         7499   \n",
       "2               2               Evening Ride   19347.2         4273   \n",
       "3               2  Afternoon Weight Training       0.0         3673   \n",
       "4               2                    K200süèéÔ∏è    9915.6         3272   \n",
       "\n",
       "   elapsed_time  total_elevation_gain     type      sport_type  workout_type  \\\n",
       "0          8140                  61.0     Ride            Ride           NaN   \n",
       "1          8179                  51.0      Run             Run           2.0   \n",
       "2          4375                  75.0     Ride            Ride          10.0   \n",
       "3          3673                   0.0  Workout  WeightTraining           NaN   \n",
       "4          3314                  10.0      Run             Run           3.0   \n",
       "\n",
       "            id  ... has_kudoed suffer_score athlete_id  \\\n",
       "0  15891685827  ...      False         11.0   81055898   \n",
       "1  15885021588  ...      False         98.0   81055898   \n",
       "2  15879687027  ...      False          8.0   81055898   \n",
       "3  15865360447  ...      False          9.0   81055898   \n",
       "4  15855640218  ...      False         60.0   81055898   \n",
       "\n",
       "   athlete_resource_state        map_id  \\\n",
       "0                       1  a15891685827   \n",
       "1                       1  a15885021588   \n",
       "2                       1  a15879687027   \n",
       "3                       1  a15865360447   \n",
       "4                       1  a15855640218   \n",
       "\n",
       "                                map_summary_polyline map_resource_state  \\\n",
       "0  ki}vHuomgBcDnFgCtEsAdBi@z@aInNWh@KvAKZQP_@B{@f...                  2   \n",
       "1  wf}vHismgBkArBaAvAWh@g@x@q@bA{AzCi@|@gApAgEpHe...                  2   \n",
       "2  oh|vHsuogBVn@XNDNAFiBjDy@hAi@f@qAxBcAvAgAdBSN[...                  2   \n",
       "3                                                                     2   \n",
       "4  or{vHq{ngBHZ^l@Vv@|@rB|@nCd@rCf@rDZtApAjEdBjF^...                  2   \n",
       "\n",
       "   average_cadence  max_watts  weighted_average_watts  \n",
       "0              NaN        NaN                     NaN  \n",
       "1             83.7      499.0                   323.0  \n",
       "2              NaN        NaN                     NaN  \n",
       "3              NaN        NaN                     NaN  \n",
       "4             82.2      546.0                   382.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_all_activities(activites_url: str, per_page: int = PER_PAGE, max_pages: int = MAX_PAGES):\n",
    "  \"\"\"\n",
    "  Fetch all activity records from a paginated API endpoint.\n",
    "\n",
    "  The function iterates through API pages until either:\n",
    "    * the maximum number of pages is reached (``max_pages``), or\n",
    "    * the API returns an empty list (end of results).\n",
    "\n",
    "  Each page is retrieved using ``get_json_with_retry`` to ensure resilience\n",
    "  against transient errors (rate limits, timeouts, 5xx responses).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activites_url : str\n",
    "      The base URL of the activities endpoint (must support ``per_page`` and ``page`` query params).\n",
    "  per_page : int, default=PER_PAGE\n",
    "      Number of activity records to request per page.\n",
    "  max_pages : int, default=MAX_PAGES\n",
    "      Maximum number of pages to fetch before stopping.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  list of dict\n",
    "      Combined list of activity objects returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  RuntimeError\n",
    "      If the API response is not a list (unexpected schema).\n",
    "  requests.exceptions.RequestException\n",
    "      If the underlying HTTP requests fail after retries.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Logs the number of records downloaded per page and the running total.\n",
    "  * Stops early if the API returns an empty list before reaching ``max_pages``.\n",
    "  * The total number of records is ``per_page * n_pages`` at most.\n",
    "  \"\"\"\n",
    "\n",
    "  all_items = []\n",
    "  page = 1\n",
    "  while page <= max_pages:\n",
    "    params = {'per_page': per_page, 'page': page}\n",
    "    data = get_json_with_retry(activites_url, params=params)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "      raise RuntimeError(f\"Unexpected response type for page {page}: {type(data)} ‚Äî expected list\")\n",
    "    \n",
    "    if not data:\n",
    "      break\n",
    "    \n",
    "    all_items.extend(data)\n",
    "    logging.info(f\"Page {page}: downloaded {len(data)} records (total: {len(all_items)})\")\n",
    "    page += 1\n",
    "  return all_items\n",
    "\n",
    "activities_raw = fetch_all_activities(ACTIVITIES_URL, per_page=PER_PAGE, max_pages=MAX_PAGES)\n",
    "logging.info(f\"Total activities downloaded: {len(activities_raw)}\")\n",
    "activities_df = pd.json_normalize(activities_raw, sep='_')\n",
    "if activities_df.empty:\n",
    "    raise RuntimeError('No activities to save.')\n",
    "activities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"average_temp\": Float,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:29:16,311 | WARNING | Whole table bronze.activities will be overwritten.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_full_name = f\"{TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"\n",
    "logging.warning(f\"Whole table {table_full_name} will be overwritten.\")\n",
    "activities_df.to_sql(\n",
    "  ACTIVITIES_B_TABLE, \n",
    "  engine, \n",
    "  schema=TARGET_B_SCHEMA, \n",
    "  if_exists=\"replace\", \n",
    "  index=False, \n",
    "  method=\"multi\", \n",
    "  chunksize=1000, \n",
    "  dtype=activities_dtype_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing details ‚Äî only `id` that are not present in `bronze.activities_details`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:29:17,285 | INFO | Missing details of 4 IDs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15865360447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15879687027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15885021588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15891685827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "0  15865360447\n",
       "1  15879687027\n",
       "2  15885021588\n",
       "3  15891685827"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE} (id BIGINT PRIMARY KEY)\n",
    "\"\"\"))\n",
    "  existing_ids = pd.read_sql(text(f\"SELECT id FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "  existing_ids_set = set(existing_ids['id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids = sorted(all_ids_set - existing_ids_set)\n",
    "logging.info(f\"Missing details of {len(missing_ids)} IDs\")\n",
    "pd.DataFrame({'id': missing_ids}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify recent activities ‚Äî update and download kudos of `id` from the last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE} (id BIGINT PRIMARY KEY)\n",
    "\"\"\"))\n",
    "  bronze_activities_df = pd.read_sql(text(f\"SELECT * FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_activities_df['date'] =  pd.to_datetime(bronze_activities_df['start_date_local']).dt.tz_localize(None)\n",
    "today = pd.Timestamp('today').normalize()\n",
    "bronze_activities_df['activity_age_days'] = (today - bronze_activities_df['date'].dt.normalize()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:30:08,202 | INFO | Refreshing details of 29 IDs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15581915542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15592776280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15606539244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15626291263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15626580466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "0  15581915542\n",
       "1  15592776280\n",
       "2  15606539244\n",
       "3  15626291263\n",
       "4  15626580466"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_activities_df = bronze_activities_df[bronze_activities_df['activity_age_days'] <= REFRESH_THRESHOLD_DAYS]\n",
    "recent_activities_ids = set(recent_activities_df['id'].astype('Int64').dropna().to_list())\n",
    "recent_activities_ids = sorted(recent_activities_ids)\n",
    "logging.info(f\"Refreshing details of {len(recent_activities_ids)} IDs\")\n",
    "pd.DataFrame({'id': recent_activities_ids}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [04:47<00:00,  8.71s/it]\n",
      "2025-09-23 12:35:48,037 | INFO | Details downloaded: 33 / 33\n"
     ]
    }
   ],
   "source": [
    "def fetch_activity_details(activity_id: int):\n",
    "  \"\"\"\n",
    "  Fetch detailed information for a single activity.\n",
    "\n",
    "  Builds the activity detail endpoint URL using the given activity ID\n",
    "  and retrieves the JSON payload with retry logic.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  activity_id : int\n",
    "      Unique identifier of the activity.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  dict\n",
    "      JSON object containing the activity details as returned by the API.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  requests.exceptions.RequestException\n",
    "      If the request fails after retries (e.g., network error, rate limit, 5xx).\n",
    "  requests.exceptions.HTTPError\n",
    "      If the server returns an error response on the last attempt.\n",
    "  json.JSONDecodeError\n",
    "      If the response cannot be parsed as JSON.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  * Uses the global template ``ACTIVITY_DETAIL_URL_TMPL`` to construct the URL.\n",
    "  * Under the hood calls ``get_json_with_retry`` for resiliency.\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_DETAIL_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "ids_to_be_downloaded = sorted(set(missing_ids) | set(recent_activities_ids))\n",
    "details_records = []\n",
    "for i, act_id in tqdm(enumerate(ids_to_be_downloaded, start=1), total=len(ids_to_be_downloaded)):\n",
    "  try:\n",
    "    resp = fetch_activity_details(act_id)\n",
    "    \n",
    "    if not isinstance(resp, dict):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "    details_records.append(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading details for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Details downloaded: {len(details_records)} / {len(ids_to_be_downloaded)}\")\n",
    "details_df_new = pd.json_normalize(details_records, sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resource_state</th>\n",
       "      <th>name</th>\n",
       "      <th>distance</th>\n",
       "      <th>moving_time</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>total_elevation_gain</th>\n",
       "      <th>type</th>\n",
       "      <th>sport_type</th>\n",
       "      <th>workout_type</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_activities_trend_direction</th>\n",
       "      <th>similar_activities_resource_state</th>\n",
       "      <th>average_temp</th>\n",
       "      <th>photos_primary_unique_id</th>\n",
       "      <th>photos_primary_urls_600</th>\n",
       "      <th>photos_primary_urls_100</th>\n",
       "      <th>photos_primary_source</th>\n",
       "      <th>photos_primary_media_type</th>\n",
       "      <th>photos_use_primary_photo</th>\n",
       "      <th>private_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Progressive Runü™¶</td>\n",
       "      <td>9762.5</td>\n",
       "      <td>3112</td>\n",
       "      <td>3309</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15581915542</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3524</td>\n",
       "      <td>3524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15592776280</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rolling 300sü™¶</td>\n",
       "      <td>9061.8</td>\n",
       "      <td>3078</td>\n",
       "      <td>3116</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Run</td>\n",
       "      <td>Run</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15606539244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Afternoon Weight Training</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>WeightTraining</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15626291263</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Afternoon Ride</td>\n",
       "      <td>12140.8</td>\n",
       "      <td>1749</td>\n",
       "      <td>6223</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Ride</td>\n",
       "      <td>Ride</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15626580466</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resource_state                       name  distance  moving_time  \\\n",
       "0               3           Progressive Runü™¶    9762.5         3112   \n",
       "1               3  Afternoon Weight Training       0.0         3524   \n",
       "2               3              Rolling 300sü™¶    9061.8         3078   \n",
       "3               3  Afternoon Weight Training       0.0         3582   \n",
       "4               3             Afternoon Ride   12140.8         1749   \n",
       "\n",
       "   elapsed_time  total_elevation_gain            type      sport_type  \\\n",
       "0          3309                  17.0             Run             Run   \n",
       "1          3524                   0.0  WeightTraining  WeightTraining   \n",
       "2          3116                   9.0             Run             Run   \n",
       "3          3582                   0.0  WeightTraining  WeightTraining   \n",
       "4          6223                  38.0            Ride            Ride   \n",
       "\n",
       "   workout_type           id  ... similar_activities_trend_direction  \\\n",
       "0           3.0  15581915542  ...                                1.0   \n",
       "1          30.0  15592776280  ...                                NaN   \n",
       "2           3.0  15606539244  ...                                0.0   \n",
       "3          30.0  15626291263  ...                                NaN   \n",
       "4          10.0  15626580466  ...                                NaN   \n",
       "\n",
       "  similar_activities_resource_state average_temp  photos_primary_unique_id  \\\n",
       "0                               2.0          NaN                       NaN   \n",
       "1                               NaN          NaN                       NaN   \n",
       "2                               2.0          NaN                       NaN   \n",
       "3                               NaN          NaN                       NaN   \n",
       "4                               NaN         25.0                       NaN   \n",
       "\n",
       "  photos_primary_urls_600 photos_primary_urls_100 photos_primary_source  \\\n",
       "0                     NaN                     NaN                   NaN   \n",
       "1                     NaN                     NaN                   NaN   \n",
       "2                     NaN                     NaN                   NaN   \n",
       "3                     NaN                     NaN                   NaN   \n",
       "4                     NaN                     NaN                   NaN   \n",
       "\n",
       "   photos_primary_media_type  photos_use_primary_photo  private_note  \n",
       "0                        NaN                       NaN           NaN  \n",
       "1                        NaN                       NaN           NaN  \n",
       "2                        NaN                       NaN           NaN  \n",
       "3                        NaN                       NaN           NaN  \n",
       "4                        NaN                       NaN           NaN  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not details_df_new.empty:\n",
    "  details_df_new = details_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  details_df_new = details_df_new.dropna(how='all')\n",
    "  \n",
    "details_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.activities_details` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_details_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"name\": Text,\n",
    "    \"distance\": Float,\n",
    "    \"moving_time\": Integer,\n",
    "    \"elapsed_time\": Integer,\n",
    "    \"total_elevation_gain\": Float,\n",
    "    \"type\": Text,\n",
    "    \"sport_type\": Text,\n",
    "    \"workout_type\": Float,\n",
    "    \"id\": BigInteger,\n",
    "    \"start_date\": Text,\n",
    "    \"start_date_local\": Text,\n",
    "    \"timezone\": Text,\n",
    "    \"utc_offset\": Float,\n",
    "    \"location_city\": Text,\n",
    "    \"location_state\": Text,\n",
    "    \"location_country\": Text,\n",
    "    \"achievement_count\": Integer,\n",
    "    \"kudos_count\": Integer,\n",
    "    \"comment_count\": Integer,\n",
    "    \"athlete_count\": Integer,\n",
    "    \"photo_count\": Integer,\n",
    "    \"trainer\": Boolean,\n",
    "    \"commute\": Boolean,\n",
    "    \"manual\": Boolean,\n",
    "    \"private\": Boolean,\n",
    "    \"visibility\": Text,\n",
    "    \"flagged\": Boolean,\n",
    "    \"gear_id\": Text,\n",
    "    \"start_latlng\": JSONB,\n",
    "    \"end_latlng\": JSONB,\n",
    "    \"average_speed\": Float,\n",
    "    \"max_speed\": Float,\n",
    "    \"average_cadence\": Float,\n",
    "    \"average_watts\": Float,\n",
    "    \"max_watts\": Float,\n",
    "    \"weighted_average_watts\": Float,\n",
    "    \"device_watts\": Boolean,\n",
    "    \"kilojoules\": Float,\n",
    "    \"has_heartrate\": Boolean,\n",
    "    \"average_heartrate\": Float,\n",
    "    \"max_heartrate\": Float,\n",
    "    \"heartrate_opt_out\": Boolean,\n",
    "    \"display_hide_heartrate_option\": Boolean,\n",
    "    \"elev_high\": Float,\n",
    "    \"elev_low\": Float,\n",
    "    \"upload_id\": BigInteger,\n",
    "    \"upload_id_str\": Text,\n",
    "    \"external_id\": Text,\n",
    "    \"from_accepted_tag\": Boolean,\n",
    "    \"pr_count\": Integer,\n",
    "    \"total_photo_count\": Integer,\n",
    "    \"has_kudoed\": Boolean,\n",
    "    \"suffer_score\": Float,\n",
    "    \"description\": Text,\n",
    "    \"calories\": Float,\n",
    "    \"perceived_exertion\": Text,\n",
    "    \"prefer_perceived_exertion\": Text,\n",
    "    \"segment_efforts\": JSONB,\n",
    "    \"splits_metric\": JSONB,\n",
    "    \"splits_standard\": JSONB,\n",
    "    \"laps\": JSONB,\n",
    "    \"best_efforts\": JSONB,\n",
    "    \"stats_visibility\": JSONB,\n",
    "    \"hide_from_home\": Boolean,\n",
    "    \"device_name\": Text,\n",
    "    \"embed_token\": Text,\n",
    "    \"available_zones\": JSONB,\n",
    "    \"athlete_id\": BigInteger,\n",
    "    \"athlete_resource_state\": Integer,\n",
    "    \"map_id\": Text,\n",
    "    \"map_polyline\": Text,\n",
    "    \"map_resource_state\": Integer,\n",
    "    \"map_summary_polyline\": Text,\n",
    "    \"gear_primary\": Boolean,\n",
    "    \"gear_name\": Text,\n",
    "    \"gear_nickname\": Text,\n",
    "    \"gear_resource_state\": Float,\n",
    "    \"gear_retired\": Boolean,\n",
    "    \"gear_distance\": Float,\n",
    "    \"gear_converted_distance\": Float,\n",
    "    \"photos_primary\": JSONB,\n",
    "    \"photos_count\": Integer,\n",
    "    \"similar_activities_effort_count\": Float,\n",
    "    \"similar_activities_average_speed\": Float,\n",
    "    \"similar_activities_min_average_speed\": Float,\n",
    "    \"similar_activities_mid_average_speed\": Float,\n",
    "    \"similar_activities_max_average_speed\": Float,\n",
    "    \"similar_activities_pr_rank\": Float,\n",
    "    \"similar_activities_frequency_milestone\": Float,\n",
    "    \"similar_activities_trend_speeds\": JSONB,\n",
    "    \"similar_activities_trend_current_activity_index\": Float,\n",
    "    \"similar_activities_trend_min_speed\": Float,\n",
    "    \"similar_activities_trend_mid_speed\": Float,\n",
    "    \"similar_activities_trend_max_speed\": Float,\n",
    "    \"similar_activities_trend_direction\": Float,\n",
    "    \"similar_activities_resource_state\": Float,\n",
    "    \"average_temp\": Float,\n",
    "    \"photos_primary_unique_id\": Text,\n",
    "    \"photos_primary_urls_600\": Text,\n",
    "    \"photos_primary_urls_100\": Text,\n",
    "    \"photos_primary_source\": Integer,\n",
    "    \"photos_primary_media_type\": Integer,\n",
    "    \"photos_use_primary_photo\": Boolean,\n",
    "    \"private_note\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.activities_details` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:49:06,726 | INFO | Activities details saved to PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "if details_df_new.empty:\n",
    "  logging.info('No new details to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    details_df_new.head(0).to_sql(\n",
    "      DETAILS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_details_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=DETAILS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE details_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    details_df_new.to_sql(\n",
    "      \"details_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_details_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = details_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in details_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{DETAILS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM details_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS details_stg;'))\n",
    "  \n",
    "    logging.info('Activities details saved to PostgreSQL.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:49:10,298 | INFO | Total number of records in bronze.activities: 1099\n",
      "2025-09-23 12:49:10,299 | INFO | Total number of records in bronze.activities_details: 1099\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    total_acts = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}\"), conn)\n",
    "    total_det = pd.read_sql(text(f\"SELECT COUNT(*) AS n FROM {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}\"), conn)\n",
    "\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{ACTIVITIES_B_TABLE}: {int(total_acts['n'][0])}\")\n",
    "logging.info(f\"Total number of records in {TARGET_B_SCHEMA}.{DETAILS_B_TABLE}: {int(total_det['n'][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing kudos ‚Äî only `activity_id` that are not present in `bronze.kudos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 12:49:12,958 | INFO | Missing kudos of 154 activities\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15891685827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15885021588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15879687027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15865360447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14489256849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_id\n",
       "0  15891685827\n",
       "1  15885021588\n",
       "2  15879687027\n",
       "3  15865360447\n",
       "4  14489256849"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "  conn.execute(text(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} (id TEXT PRIMARY KEY, activity_id BIGINT)\n",
    "\"\"\"))\n",
    "  existing_ids_kudos = pd.read_sql(text(f\"SELECT activity_id FROM {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\"), conn)\n",
    "  existing_ids_kudos_set = set(existing_ids_kudos['activity_id'].astype('Int64').dropna().to_list())\n",
    "\n",
    "all_ids_kudos_set = set(activities_df['id'].astype('Int64').dropna().to_list())\n",
    "missing_ids_kudos = sorted(all_ids_kudos_set - existing_ids_kudos_set, reverse=True)\n",
    "logging.info(f\"Missing kudos of {len(missing_ids_kudos)} activities\")\n",
    "pd.DataFrame({'activity_id': missing_ids_kudos}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download activities kudos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 174/183 [24:49<01:10,  7.83s/it]2025-09-23 13:14:15,748 | WARNING | HTTP 429 - wait 15s (attempt 1/5)\n",
      "2025-09-23 13:14:31,129 | WARNING | HTTP 429 - wait 16.0s (attempt 2/5)\n",
      "2025-09-23 13:14:47,369 | WARNING | HTTP 429 - wait 24.0s (attempt 3/5)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 183/183 [26:59<00:00,  8.85s/it]\n",
      "2025-09-23 13:16:25,915 | INFO | Kudos downloaded: 332 / 183\n"
     ]
    }
   ],
   "source": [
    "def fetch_activity_kudos(activity_id: int):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  url = ACTIVITY_KUDOS_URL_TMPL.format(id=activity_id)\n",
    "  return get_json_with_retry(url, params=None)\n",
    "\n",
    "kudos_to_be_downloaded = sorted(set(missing_ids_kudos) | set(recent_activities_ids))\n",
    "\n",
    "kudos_records = []\n",
    "for i, act_id in tqdm(enumerate(kudos_to_be_downloaded, start=1), total=len(kudos_to_be_downloaded)):\n",
    "  try:\n",
    "    resp = fetch_activity_kudos(act_id)\n",
    "    \n",
    "    if not isinstance(resp, list):\n",
    "      logging.warning(f\"id={act_id}: unexpected response type ({type(resp)}), skip\")\n",
    "      continue\n",
    "\n",
    "    for i, kudos in enumerate(resp):\n",
    "      kudos[\"activity_id\"] = act_id\n",
    "      kudos[\"kudos_id\"] = i\n",
    "    kudos_records.extend(resp)\n",
    "    \n",
    "  except Exception as e:\n",
    "    logging.error(f\"Error downloading kudos for id={act_id}: {e}\")\n",
    "  \n",
    "  time.sleep(random.randint(7, 9))\n",
    "\n",
    "logging.info(f\"Kudos downloaded: {len(kudos_records)} / {len(kudos_to_be_downloaded)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kudos_df_new = pd.json_normalize(kudos_records, sep='_')\n",
    "if not kudos_df_new.empty:\n",
    "  kudos_df_new = kudos_df_new.drop(['message', 'errors'], axis=1, errors='ignore')\n",
    "  kudos_df_new = kudos_df_new.dropna(how='all')\n",
    "  \n",
    "kudos_df_new['id'] = kudos_df_new[['activity_id', 'kudos_id']].astype(\"string\").agg(\"-\".join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kudos_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set `bronze.kudos` types map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_kudos_dtype_map = {\n",
    "    \"resource_state\": Integer,\n",
    "    \"first_name\": Text,\n",
    "    \"last_name\": Float,\n",
    "    \"activity_id\": BigInteger,\n",
    "    \"id\": Text\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `bronze.kudos` to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kudos_df_new.empty:\n",
    "  logging.info('No new kudos to be saved.')\n",
    "else:\n",
    "  insp = inspect(engine)\n",
    "\n",
    "  # 1) Check if table exists in PostgreSQL\n",
    "  if not insp.has_table(table_name=KUDOS_B_TABLE, schema=TARGET_B_SCHEMA):\n",
    "    kudos_df_new.head(0).to_sql(\n",
    "      KUDOS_B_TABLE, \n",
    "      engine, \n",
    "      schema=TARGET_B_SCHEMA,\n",
    "      if_exists=\"append\", \n",
    "      index=False, \n",
    "      dtype=activities_kudos_dtype_map\n",
    "    )\n",
    "\n",
    "    # 2) Check if primary key exists\n",
    "  insp = inspect(engine)\n",
    "  pk = insp.get_pk_constraint(table_name=KUDOS_B_TABLE, schema=TARGET_B_SCHEMA)\n",
    "  if not pk.get(\"constrained_columns\"):\n",
    "    with engine.begin() as conn:\n",
    "      conn.execute(text(f'''\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\n",
    "        ALTER COLUMN \"id\" SET NOT NULL;\n",
    "        ALTER TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE}\n",
    "        ADD PRIMARY KEY (\"id\");\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # 3) Staging\n",
    "  with engine.begin() as conn:\n",
    "\n",
    "    #Temp table\n",
    "    conn.execute(text(f'''\n",
    "        CREATE TEMP TABLE kudos_stg\n",
    "        AS TABLE {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} WITH NO DATA\n",
    "      '''\n",
    "      ))\n",
    "    \n",
    "    # Load data to temp table\n",
    "    kudos_df_new.to_sql(\n",
    "      \"kudos_stg\", \n",
    "      conn, \n",
    "      if_exists=\"append\",\n",
    "      index=False, \n",
    "      method=\"multi\", \n",
    "      chunksize=5000, \n",
    "      dtype=activities_kudos_dtype_map\n",
    "      )\n",
    "    \n",
    "    # Prepare upsert\n",
    "    stg_cols = kudos_df_new.columns.to_list()\n",
    "    \n",
    "    if not 'id' in stg_cols:\n",
    "      raise RuntimeError('Column \"id\" is required in kudos_df_new to perform UPSERT.')\n",
    "    \n",
    "    cols_csv = ', '.join(f'\"{c}\"' for c in stg_cols)\n",
    "    set_csv  = ', '.join(f'\"{c}\" = EXCLUDED.\"{c}\"' for c in stg_cols if c != 'id')\n",
    "\n",
    "    upsert_sql = f'''\n",
    "        INSERT INTO {TARGET_B_SCHEMA}.{KUDOS_B_TABLE} ({cols_csv})\n",
    "        SELECT {cols_csv} FROM kudos_stg\n",
    "        ON CONFLICT (\"id\") DO UPDATE\n",
    "        SET {set_csv};\n",
    "      '''\n",
    "    conn.execute(text(upsert_sql))\n",
    "\n",
    "    # Clean up\n",
    "    conn.execute(text('DROP TABLE IF EXISTS kudos_stg;'))\n",
    "  \n",
    "    logging.info('Activities kudos saved to PostgreSQL.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "strava-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
